{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c00dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import  datetime, timedelta\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    " \n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langfuse import Langfuse\n",
    "from langfuse.openai import AzureOpenAI\n",
    " \n",
    "load_dotenv()\n",
    " \n",
    "langfuse = Langfuse()  # Auto-reads LANGFUSE_* env vars\n",
    " \n",
    "AZURE_CLIENT = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-08-01-preview\",\n",
    ")\n",
    "JUDGE_MODEL = os.getenv(\"AZURE_OPENAI_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bd14d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       " 'timestamp': datetime.datetime(2025, 11, 20, 9, 28, 20, 473000, tzinfo=datetime.timezone.utc),\n",
       " 'name': 'call_llm',\n",
       " 'input': {'model': 'azure/gpt-4o-mini',\n",
       "  'config': {'system_instruction': '\\n        **Role:** Host agent for the agent-to-agent protocol; delegates queries to specialized remote agents with maximum efficiency.\\n\\n**Core Directives:**\\n\\n* **Task Delegation:** Use the `send_message` function to assign precise, actionable tasks to remote agents.\\n* **Full Context Provision:** If an agent repeatedly asks for user confirmation, it likely lacks conversation history. Include all relevant context in the task to prevent this.\\n* **Autonomous Multi-Agent Engagement:** Engage any required agents directly—never seek user permission or preference. If multiple agents are needed, orchestrate them seamlessly.\\n* **Intelligent Inter-Agent Collaboration:** Instruct agents to determine if they need data from another agent. **If Agent A says \"I need X to proceed\" and Agent B can provide X, immediately query Agent B, then resubmit the updated task to Agent A.**\\n* **Transparent Output:** Deliver the full, unedited response from the final agent(s) to the user.\\n* **Confirmation Handling:** Only relay confirmation requests to the user if not already provided. Never confirm on behalf of the user.\\n* **Minimal Context Sharing:** Share only task-relevant context with each agent. Omit irrelevant details.\\n* **No Redundancy:** Never ask agents to confirm actions or information.\\n* **Tool-Only Responses:** Rely exclusively on tools and agents. If data is missing, request clarification from the user—never assume.\\n* **Recency Priority:** Base decisions on the most recent user message.\\n* **Active Agent Routing:** Route follow-up queries to the currently active agent using task updates.\\n\\n**Efficiency Rule:** \\n> **Dependency Resolution Loop:**  \\n> If Agent A blocks on missing info → Identify Agent B that can supply it → Query B → Feed result back to A → Repeat until A completes or escalates.\\n        **Agent Roster:**\\n\\n        * Available Agents: `{\"name\": \"Capital Agent\", \"description\": \"Answers capital-city questions for any country\"}\\n{\"name\": \"General Q&A Agent\", \"description\": \"Answers everyday questions on any topic \\\\u2014 weather, facts, how-to, recommendations, and more.\"}`\\n        * Currently Active Seller Agent: `Capital Agent`\\n                \\n\\nYou are an agent. Your internal name is \"Routing_agent\". The description about you is \"This Routing agent orchestrates the decomposition of the user asking for department or manager information.\".',\n",
       "   'tools': [{'function_declarations': [{'description': 'Sends a task to remote seller agent.\\n\\nThis will send a message to the remote agent named agent_name.\\n\\nArgs:\\n    agent_name: The name of the agent to send the task to.\\n    task: The comprehensive conversation context summary\\n        and goal to be achieved regarding user inquiry and purchase request.\\n    tool_context: The tool context this method runs in.\\n\\nYields:\\n    A dictionary of JSON data.\\n',\n",
       "       'name': 'send_message',\n",
       "       'parameters': {'properties': {'agent_name': {'type': 'STRING'},\n",
       "         'task': {'type': 'STRING'}},\n",
       "        'required': ['agent_name', 'task'],\n",
       "        'type': 'OBJECT'},\n",
       "       'response': {}}]}],\n",
       "   'labels': {'adk_agent_name': 'Routing_agent'}},\n",
       "  'contents': [{'parts': [{'text': 'what is the capital of Pakistan and write 10 lines about it.'}],\n",
       "    'role': 'user'},\n",
       "   {'parts': [{'function_call': {'id': 'call_2kkSR1RTSkhmWq7mei1gcBgB',\n",
       "       'args': {'agent_name': 'Capital Agent',\n",
       "        'task': 'User requested the capital of Pakistan and a 10-line description about it.'},\n",
       "       'name': 'send_message'}}],\n",
       "    'role': 'model'},\n",
       "   {'parts': [{'function_response': {'id': 'call_2kkSR1RTSkhmWq7mei1gcBgB',\n",
       "       'name': 'send_message',\n",
       "       'response': {'result': {'artifacts': [{'artifactId': '3d9b7caa-07e0-45c0-a38a-cc8e3948cdac',\n",
       "           'parts': [{'kind': 'text', 'text': 'Islamabad'}]}],\n",
       "         'contextId': 'b6b6d2ce-ca8a-43e5-adbe-999eba9ebd1c',\n",
       "         'history': [{'contextId': 'b6b6d2ce-ca8a-43e5-adbe-999eba9ebd1c',\n",
       "           'kind': 'message',\n",
       "           'messageId': '2aff8a91-f6c0-4fe4-8b98-45aff71b2cf3',\n",
       "           'parts': [{'kind': 'text', 'text': 'Islamabad'}],\n",
       "           'role': 'agent'}],\n",
       "         'id': '998fde21-2f6a-4116-8669-b48ad0d278d9',\n",
       "         'kind': 'task',\n",
       "         'status': {'state': 'completed'}}}}}],\n",
       "    'role': 'user'}]},\n",
       " 'output': {'content': {'parts': [{'function_call': {'id': 'call_pQA9a3Ea1lmhaEp6r4EdsWto',\n",
       "      'args': {'agent_name': 'General Q&A Agent',\n",
       "       'task': 'User asked for a 10-line description of Islamabad, the capital of Pakistan.'},\n",
       "      'name': 'send_message'}}],\n",
       "   'role': 'model'},\n",
       "  'partial': False,\n",
       "  'usage_metadata': {'candidates_token_count': 38,\n",
       "   'prompt_token_count': 921,\n",
       "   'total_token_count': 959}},\n",
       " 'metadata': {'attributes': {'gen_ai.system': 'gcp.vertex.agent',\n",
       "   'gen_ai.request.model': 'azure/gpt-4o-mini',\n",
       "   'gcp.vertex.agent.invocation_id': 'e-1773c2c0-9fb0-4741-bf2f-4936346cf4da',\n",
       "   'gcp.vertex.agent.session_id': 'default_session',\n",
       "   'gcp.vertex.agent.event_id': '5de324d5-9cd4-470e-b86c-83dbc92187b3',\n",
       "   'gen_ai.usage.input_tokens': '921',\n",
       "   'gen_ai.usage.output_tokens': '38'},\n",
       "  'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "   'telemetry.sdk.name': 'opentelemetry',\n",
       "   'telemetry.sdk.version': '1.38.0',\n",
       "   'service.name': 'unknown_service'},\n",
       "  'scope': {'name': 'gcp.vertex.agent',\n",
       "   'version': '1.17.0',\n",
       "   'attributes': {}}},\n",
       " 'tags': [],\n",
       " 'public': False,\n",
       " 'environment': 'default',\n",
       " 'htmlPath': '/project/cmhwzwyvs01fjad07xfmlp94h/traces/3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       " 'latency': 8.731,\n",
       " 'totalCost': 0.0,\n",
       " 'observations': [{'id': '6eda86706e8e2b96',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'type': 'AGENT',\n",
       "   'name': 'rohit',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 9, 28, 23, 210000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 9, 28, 29, 196000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': {},\n",
       "   'input': {'args': [],\n",
       "    'kwargs': {'message_request': {'id': 'ed341398-ed9e-4d38-bf1f-2676650741c3',\n",
       "      'jsonrpc': '2.0',\n",
       "      'method': 'message/send',\n",
       "      'params': {'configuration': None,\n",
       "       'message': {'contextId': '2b2860c5-50fe-4b8e-9ba6-cc77817fd6d7',\n",
       "        'extensions': None,\n",
       "        'kind': 'message',\n",
       "        'messageId': 'ed341398-ed9e-4d38-bf1f-2676650741c3',\n",
       "        'metadata': None,\n",
       "        'parts': [{'kind': 'text',\n",
       "          'metadata': None,\n",
       "          'text': 'User asked for a 10-line description of Islamabad, the capital of Pakistan.'}],\n",
       "        'referenceTaskIds': None,\n",
       "        'role': 'user',\n",
       "        'taskId': None},\n",
       "       'metadata': None}}}},\n",
       "   'version': None,\n",
       "   'metadata': {'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'langfuse-sdk',\n",
       "     'version': '3.10.0',\n",
       "     'attributes': {'public_key': 'pk-lf-f69fce2c-2a85-44c6-8777-646b07f7ccaf'}}},\n",
       "   'output': {'id': 'ed341398-ed9e-4d38-bf1f-2676650741c3',\n",
       "    'jsonrpc': '2.0',\n",
       "    'result': {'artifacts': [{'artifactId': '22299dc1-62cd-4858-aa76-32eb0b695121',\n",
       "       'description': None,\n",
       "       'extensions': None,\n",
       "       'metadata': None,\n",
       "       'name': None,\n",
       "       'parts': [{'kind': 'text',\n",
       "         'metadata': None,\n",
       "         'text': \"Islamabad is the capital city of Pakistan, officially established in 1967 to replace Karachi as the nation's capital. Located in the northern part of the country near the Margalla Hills, the city was purposefully designed and built as a modern planned capital. The city is known for its well-organized layout, wide tree-lined avenues, and systematic sectoral divisions that create an orderly urban environment. Islamabad houses important government buildings, including the Presidential Palace, Parliament House, and Supreme Court of Pakistan. The city is characterized by its clean, green environment with numerous parks, gardens, and the scenic Margalla Hills National Park nearby. Home to several prestigious educational institutions like Quaid-i-Azam University and the International Islamic University, it serves as an important academic center. The population is diverse, consisting of government officials, diplomats, professionals, and students from across Pakistan and abroad. Islamabad's economy is primarily based on government services, though it also has growing technology and business sectors. The city experiences a humid subtropical climate with hot summers and mild winters. As Pakistan's political and administrative center, Islamabad plays a crucial role in the country's governance and international diplomatic relations.\"}]}],\n",
       "     'contextId': '2b2860c5-50fe-4b8e-9ba6-cc77817fd6d7',\n",
       "     'history': [{'contextId': '2b2860c5-50fe-4b8e-9ba6-cc77817fd6d7',\n",
       "       'extensions': None,\n",
       "       'kind': 'message',\n",
       "       'messageId': 'ed341398-ed9e-4d38-bf1f-2676650741c3',\n",
       "       'metadata': None,\n",
       "       'parts': [{'kind': 'text',\n",
       "         'metadata': None,\n",
       "         'text': \"Islamabad is the capital city of Pakistan, officially established in 1967 to replace Karachi as the nation's capital. Located in the northern part of the country near the Margalla Hills, the city was purposefully designed and built as a modern planned capital. The city is known for its well-organized layout, wide tree-lined avenues, and systematic sectoral divisions that create an orderly urban environment. Islamabad houses important government buildings, including the Presidential Palace, Parliament House, and Supreme Court of Pakistan. The city is characterized by its clean, green environment with numerous parks, gardens, and the scenic Margalla Hills National Park nearby. Home to several prestigious educational institutions like Quaid-i-Azam University and the International Islamic University, it serves as an important academic center. The population is diverse, consisting of government officials, diplomats, professionals, and students from across Pakistan and abroad. Islamabad's economy is primarily based on government services, though it also has growing technology and business sectors. The city experiences a humid subtropical climate with hot summers and mild winters. As Pakistan's political and administrative center, Islamabad plays a crucial role in the country's governance and international diplomatic relations.\"}],\n",
       "       'referenceTaskIds': None,\n",
       "       'role': 'agent',\n",
       "       'taskId': None}],\n",
       "     'id': 'fac87679-acbf-4405-bfb3-36f7bd9e3f3a',\n",
       "     'kind': 'task',\n",
       "     'metadata': None,\n",
       "     'status': {'message': None, 'state': 'completed', 'timestamp': None}}},\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': 'bfd858f112cad05f',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 5986.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'createdAt': '2025-11-20T09:28:31.988Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'promptTokens': 0,\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T09:28:31.988Z',\n",
       "   'unit': 'TOKENS'},\n",
       "  {'id': 'a9e7e75088e2edca',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'type': 'GENERATION',\n",
       "   'name': 'call_llm',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 9, 28, 20, 473000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 9, 28, 29, 204000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': 'azure/gpt-4o-mini',\n",
       "   'modelParameters': {},\n",
       "   'input': {'model': 'azure/gpt-4o-mini',\n",
       "    'config': {'system_instruction': '\\n        **Role:** Host agent for the agent-to-agent protocol; delegates queries to specialized remote agents with maximum efficiency.\\n\\n**Core Directives:**\\n\\n* **Task Delegation:** Use the `send_message` function to assign precise, actionable tasks to remote agents.\\n* **Full Context Provision:** If an agent repeatedly asks for user confirmation, it likely lacks conversation history. Include all relevant context in the task to prevent this.\\n* **Autonomous Multi-Agent Engagement:** Engage any required agents directly—never seek user permission or preference. If multiple agents are needed, orchestrate them seamlessly.\\n* **Intelligent Inter-Agent Collaboration:** Instruct agents to determine if they need data from another agent. **If Agent A says \"I need X to proceed\" and Agent B can provide X, immediately query Agent B, then resubmit the updated task to Agent A.**\\n* **Transparent Output:** Deliver the full, unedited response from the final agent(s) to the user.\\n* **Confirmation Handling:** Only relay confirmation requests to the user if not already provided. Never confirm on behalf of the user.\\n* **Minimal Context Sharing:** Share only task-relevant context with each agent. Omit irrelevant details.\\n* **No Redundancy:** Never ask agents to confirm actions or information.\\n* **Tool-Only Responses:** Rely exclusively on tools and agents. If data is missing, request clarification from the user—never assume.\\n* **Recency Priority:** Base decisions on the most recent user message.\\n* **Active Agent Routing:** Route follow-up queries to the currently active agent using task updates.\\n\\n**Efficiency Rule:** \\n> **Dependency Resolution Loop:**  \\n> If Agent A blocks on missing info → Identify Agent B that can supply it → Query B → Feed result back to A → Repeat until A completes or escalates.\\n        **Agent Roster:**\\n\\n        * Available Agents: `{\"name\": \"Capital Agent\", \"description\": \"Answers capital-city questions for any country\"}\\n{\"name\": \"General Q&A Agent\", \"description\": \"Answers everyday questions on any topic \\\\u2014 weather, facts, how-to, recommendations, and more.\"}`\\n        * Currently Active Seller Agent: `Capital Agent`\\n                \\n\\nYou are an agent. Your internal name is \"Routing_agent\". The description about you is \"This Routing agent orchestrates the decomposition of the user asking for department or manager information.\".',\n",
       "     'tools': [{'function_declarations': [{'description': 'Sends a task to remote seller agent.\\n\\nThis will send a message to the remote agent named agent_name.\\n\\nArgs:\\n    agent_name: The name of the agent to send the task to.\\n    task: The comprehensive conversation context summary\\n        and goal to be achieved regarding user inquiry and purchase request.\\n    tool_context: The tool context this method runs in.\\n\\nYields:\\n    A dictionary of JSON data.\\n',\n",
       "         'name': 'send_message',\n",
       "         'parameters': {'properties': {'agent_name': {'type': 'STRING'},\n",
       "           'task': {'type': 'STRING'}},\n",
       "          'required': ['agent_name', 'task'],\n",
       "          'type': 'OBJECT'},\n",
       "         'response': {}}]}],\n",
       "     'labels': {'adk_agent_name': 'Routing_agent'}},\n",
       "    'contents': [{'parts': [{'text': 'what is the capital of Pakistan and write 10 lines about it.'}],\n",
       "      'role': 'user'},\n",
       "     {'parts': [{'function_call': {'id': 'call_2kkSR1RTSkhmWq7mei1gcBgB',\n",
       "         'args': {'agent_name': 'Capital Agent',\n",
       "          'task': 'User requested the capital of Pakistan and a 10-line description about it.'},\n",
       "         'name': 'send_message'}}],\n",
       "      'role': 'model'},\n",
       "     {'parts': [{'function_response': {'id': 'call_2kkSR1RTSkhmWq7mei1gcBgB',\n",
       "         'name': 'send_message',\n",
       "         'response': {'result': {'artifacts': [{'artifactId': '3d9b7caa-07e0-45c0-a38a-cc8e3948cdac',\n",
       "             'parts': [{'kind': 'text', 'text': 'Islamabad'}]}],\n",
       "           'contextId': 'b6b6d2ce-ca8a-43e5-adbe-999eba9ebd1c',\n",
       "           'history': [{'contextId': 'b6b6d2ce-ca8a-43e5-adbe-999eba9ebd1c',\n",
       "             'kind': 'message',\n",
       "             'messageId': '2aff8a91-f6c0-4fe4-8b98-45aff71b2cf3',\n",
       "             'parts': [{'kind': 'text', 'text': 'Islamabad'}],\n",
       "             'role': 'agent'}],\n",
       "           'id': '998fde21-2f6a-4116-8669-b48ad0d278d9',\n",
       "           'kind': 'task',\n",
       "           'status': {'state': 'completed'}}}}}],\n",
       "      'role': 'user'}]},\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {'gen_ai.system': 'gcp.vertex.agent',\n",
       "     'gen_ai.request.model': 'azure/gpt-4o-mini',\n",
       "     'gcp.vertex.agent.invocation_id': 'e-1773c2c0-9fb0-4741-bf2f-4936346cf4da',\n",
       "     'gcp.vertex.agent.session_id': 'default_session',\n",
       "     'gcp.vertex.agent.event_id': '5de324d5-9cd4-470e-b86c-83dbc92187b3',\n",
       "     'gen_ai.usage.input_tokens': '921',\n",
       "     'gen_ai.usage.output_tokens': '38'},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'gcp.vertex.agent',\n",
       "     'version': '1.17.0',\n",
       "     'attributes': {}}},\n",
       "   'output': {'content': {'parts': [{'function_call': {'id': 'call_pQA9a3Ea1lmhaEp6r4EdsWto',\n",
       "        'args': {'agent_name': 'General Q&A Agent',\n",
       "         'task': 'User asked for a 10-line description of Islamabad, the capital of Pakistan.'},\n",
       "        'name': 'send_message'}}],\n",
       "     'role': 'model'},\n",
       "    'partial': False,\n",
       "    'usage_metadata': {'candidates_token_count': 38,\n",
       "     'prompt_token_count': 921,\n",
       "     'total_token_count': 959}},\n",
       "   'usage': {'input': 921,\n",
       "    'output': 38,\n",
       "    'total': 959,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': None,\n",
       "   'promptId': None,\n",
       "   'usageDetails': {'input': 921, 'output': 38, 'total': 959},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 8731.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 959,\n",
       "   'createdAt': '2025-11-20T09:28:31.988Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'promptTokens': 921,\n",
       "   'completionTokens': 38,\n",
       "   'updatedAt': '2025-11-20T09:28:31.988Z',\n",
       "   'unit': 'TOKENS'},\n",
       "  {'id': '36d37b6e55229026',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport.send_message',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 9, 28, 23, 210000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 9, 28, 29, 196000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'version': '1.0.0', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': '6eda86706e8e2b96',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 5986.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'createdAt': '2025-11-20T09:28:31.988Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'promptTokens': 0,\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T09:28:31.988Z',\n",
       "   'unit': 'TOKENS'},\n",
       "  {'id': '8b881a2370954903',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport._send_request',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 9, 28, 23, 211000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 9, 28, 29, 196000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'version': '1.0.0', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': '36d37b6e55229026',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 5985.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'createdAt': '2025-11-20T09:28:31.988Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'promptTokens': 0,\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T09:28:31.988Z',\n",
       "   'unit': 'TOKENS'},\n",
       "  {'id': 'bfd858f112cad05f',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'type': 'TOOL',\n",
       "   'name': 'execute_tool send_message',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 9, 28, 23, 209000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 9, 28, 29, 199000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': {},\n",
       "   'input': {'agent_name': 'General Q&A Agent',\n",
       "    'task': 'User asked for a 10-line description of Islamabad, the capital of Pakistan.'},\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {'gen_ai.operation.name': 'execute_tool',\n",
       "     'gen_ai.tool.description': 'Sends a task to remote seller agent.\\n\\nThis will send a message to the remote agent named agent_name.\\n\\nArgs:\\n    agent_name: The name of the agent to send the task to.\\n    task: The comprehensive conversation context summary\\n        and goal to be achieved regarding user inquiry and purchase request.\\n    tool_context: The tool context this method runs in.\\n\\nYields:\\n    A dictionary of JSON data.',\n",
       "     'gen_ai.tool.name': 'send_message',\n",
       "     'gen_ai.tool.type': 'FunctionTool',\n",
       "     'gen_ai.tool.call.id': 'call_pQA9a3Ea1lmhaEp6r4EdsWto',\n",
       "     'gcp.vertex.agent.event_id': '0e7c0a2c-01dc-48f4-9730-70b176b8cb9e'},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'gcp.vertex.agent',\n",
       "     'version': '1.17.0',\n",
       "     'attributes': {}}},\n",
       "   'output': {'result': '<not serializable>'},\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': 'a9e7e75088e2edca',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 5990.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'createdAt': '2025-11-20T09:28:31.988Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'promptTokens': 0,\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T09:28:31.988Z',\n",
       "   'unit': 'TOKENS'},\n",
       "  {'id': 'd28642acb4e842bb',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport._apply_interceptors',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 9, 28, 23, 211000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 9, 28, 23, 211000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'version': '1.0.0', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': '36d37b6e55229026',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 0.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'createdAt': '2025-11-20T09:28:26.608Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'promptTokens': 0,\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T09:28:26.609Z',\n",
       "   'unit': 'TOKENS'},\n",
       "  {'id': '2505fd8e73f7c16d',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport._get_http_args',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 9, 28, 23, 210000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 9, 28, 23, 210000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': '36d37b6e55229026',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 0.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'createdAt': '2025-11-20T09:28:26.608Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'promptTokens': 0,\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T09:28:26.608Z',\n",
       "   'unit': 'TOKENS'}],\n",
       " 'scores': [{'value': 0.0,\n",
       "   'id': '6bcc53b17fb33983',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'conciseness',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 26, 162000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 28, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 32, 288000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Final answer not verbose',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '63a487a29f5382eb',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'task_success_binary',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 26, 162000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 28, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 32, 284000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Strict pass/fail (goal_completion ≥ 0.9)',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '36dcd72ac7de1c93',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'hallucinated_tool_output',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 26, 162000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 28, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 32, 280000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': '1.0 = no fake tool results (lower = bad)',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '696534c88dbb8d42',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'latency_seconds',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 26, 162000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 28, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 32, 280000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'End-to-end latency in seconds',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '5c7ca1e2cfbb9414',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'reasoning_quality',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 26, 162000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 28, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 32, 278000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Logical intermediate reasoning?',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '9789174f0f23c354',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'total_tokens',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 26, 162000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 28, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 32, 277000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Total tokens used',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': 'd90d28a15368bd97',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'tool_selection_accuracy',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 26, 162000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 28, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 32, 276000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Correct tools chosen and ordered?',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '88622a578fd95203',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'total_steps',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 26, 162000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 28, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 32, 276000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Number of reasoning/tool steps (lower = more efficient)',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '2956c4886e1b52bf',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'goal_completion',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 26, 162000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 26, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 30, 938000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': \"Did the agent fully solve the user's goal?\",\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '53d597a9165e7fdc',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'hallucinated_tool_output',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 9, 192000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 10, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 14, 509000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': '1.0 = no fake tool results (lower = bad)',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '6d7827c3f71ca0e6',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'goal_completion',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 9, 192000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 10, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 14, 507000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': \"Did the agent fully solve the user's goal?\",\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '0f424bf3a51c471b',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'total_tokens',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 9, 199000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 10, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 14, 500000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Total tokens used',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '26f9d3235bc44317',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'reasoning_quality',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 9, 192000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 10, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 14, 496000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Logical intermediate reasoning?',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '599d0acffd46d213',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'task_success_binary',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 9, 199000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 10, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 14, 495000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Strict pass/fail (goal_completion ≥ 0.9)',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '60b010b4a6dcc465',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'conciseness',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 9, 192000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 10, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 14, 491000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Final answer not verbose',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': 'aea234be4b03a90e',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'latency_seconds',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 9, 192000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 10, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 14, 491000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'End-to-end latency in seconds',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': 'd7b852ea64b426a3',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'tool_selection_accuracy',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 9, 192000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 10, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 14, 490000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Correct tools chosen and ordered?',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None},\n",
       "  {'value': 0.0,\n",
       "   'id': '9b1f04aabaa47b72',\n",
       "   'traceId': '3c7300a2c603e23e4cd87f07cdc5c34f',\n",
       "   'name': 'total_steps',\n",
       "   'source': <ScoreSource.API: 'API'>,\n",
       "   'observationId': None,\n",
       "   'timestamp': datetime.datetime(2025, 11, 20, 13, 58, 9, 192000, tzinfo=datetime.timezone.utc),\n",
       "   'createdAt': datetime.datetime(2025, 11, 20, 13, 58, 10, tzinfo=datetime.timezone.utc),\n",
       "   'updatedAt': datetime.datetime(2025, 11, 20, 13, 58, 14, 484000, tzinfo=datetime.timezone.utc),\n",
       "   'authorUserId': None,\n",
       "   'comment': 'Number of reasoning/tool steps (lower = more efficient)',\n",
       "   'metadata': {},\n",
       "   'configId': None,\n",
       "   'queueId': None,\n",
       "   'environment': 'default',\n",
       "   'dataType': 'NUMERIC',\n",
       "   'executionTraceId': None,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'stringValue': None}],\n",
       " 'bookmarked': False,\n",
       " 'createdAt': '2025-11-20T09:28:27.000Z',\n",
       " 'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       " 'updatedAt': '2025-11-20T09:28:32.069Z',\n",
       " 'sessionId': None,\n",
       " 'release': None,\n",
       " 'version': None,\n",
       " 'userId': None,\n",
       " 'externalId': None}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = langfuse.api.trace.get(\"3c7300a2c603e23e4cd87f07cdc5c34f\")\n",
    "y=x.dict()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd19ded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of Pakistan and write 10 lines about it.\n",
      "Islamabad is the capital city of Pakistan, officially established in 1967 to replace Karachi as the nation's capital. Located in the northern part of the country near the Margalla Hills, the city was purposefully designed and built as a modern planned capital. The city is known for its well-organized layout, wide tree-lined avenues, and systematic sectoral divisions that create an orderly urban environment. Islamabad houses important government buildings, including the Presidential Palace, Parliament House, and Supreme Court of Pakistan. The city is characterized by its clean, green environment with numerous parks, gardens, and the scenic Margalla Hills National Park nearby. Home to several prestigious educational institutions like Quaid-i-Azam University and the International Islamic University, it serves as an important academic center. The population is diverse, consisting of government officials, diplomats, professionals, and students from across Pakistan and abroad. Islamabad's economy is primarily based on government services, though it also has growing technology and business sectors. The city experiences a humid subtropical climate with hot summers and mild winters. As Pakistan's political and administrative center, Islamabad plays a crucial role in the country's governance and international diplomatic relations.\n",
      "[\"Agent 'Capital Agent' is assigned a task User requested the capital of \"\n",
      " 'Pakistan and a 10-line description about it.',\n",
      " 'Agent response: Islamabad',\n",
      " \"Final Agent 'General Q&A Agent' was assigned a task User asked for a 10-line \"\n",
      " 'description of Islamabad, the capital of Pakistan.']\n"
     ]
    }
   ],
   "source": [
    "input= y[\"input\"][\"contents\"][0][\"parts\"][0][\"text\"]\n",
    "print(input)\n",
    "output=y[\"observations\"][0][\"output\"][\"result\"][\"artifacts\"][0][\"parts\"][0][\"text\"]\n",
    "print(output)\n",
    "steps = []\n",
    "import pprint\n",
    "for item in y[\"input\"][\"contents\"]:\n",
    "    parts = item.get(\"parts\", [])\n",
    "    for part in parts:\n",
    "        if \"function_call\" in part:\n",
    "            args = part[\"function_call\"][\"args\"]\n",
    "            steps.append(f\"Agent '{args.get('agent_name')}' is assigned a task {args.get('task')}\")\n",
    "\n",
    "        if \"function_response\" in part:\n",
    "            artifacts = part[\"function_response\"][\"response\"][\"result\"][\"artifacts\"]\n",
    "            collected_texts = []\n",
    "            for artifact in artifacts:\n",
    "                for p in artifact.get(\"parts\", []):\n",
    "                    if p.get(\"kind\") == \"text\":\n",
    "                        collected_texts.append(p.get(\"text\"))\n",
    "            steps.append(f\"Agent response: {' '.join(collected_texts)}\")\n",
    "\n",
    "output_parts = y[\"output\"][\"content\"].get(\"parts\", [])\n",
    "collected_texts = []\n",
    "for part in output_parts:\n",
    "    if \"function_call\" in part:\n",
    "        args = part[\"function_call\"][\"args\"]\n",
    "        collected_texts.append(f\"Agent '{args.get('agent_name')}' was assigned a task {args.get('task')}\")\n",
    "\n",
    "steps.append(f\"Final {' '.join(collected_texts)}\")\n",
    "\n",
    "pprint.pprint(steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6333bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_tool_calls(trace) -> str:\n",
    "#     tools = []\n",
    "#     for span in getattr(trace, \"spans\", []) or []:\n",
    "#         name = getattr(span, \"name\", \"\")\n",
    "#         if name in [\"tool\", \"function\", \"retriever\"] or (\"tool\" in name.lower()):\n",
    "#             tools.append(f\"- {name}: {getattr(span, 'input', '')}\")\n",
    "#     return \"\\n\".join(tools) or \"No tools used\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c3ff0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tool_calls(trace) -> int:\n",
    "    \"\"\"\n",
    "    Accurately counts the number of agent reasoning steps:\n",
    "    - Each LLM generation (call_llm)\n",
    "    - Each meaningful tool execution (especially send_message to remote agents)\n",
    "    \"\"\"\n",
    "    observations = trace.get('observations', [])\n",
    "    \n",
    "    llm_calls = 0\n",
    "    tool_calls = 0\n",
    "\n",
    "    for obs in observations:\n",
    "        obs_type = obs.get('type')\n",
    "        obs_name = str(obs.get('name', '')).lower()\n",
    "        if obs_type == 'GENERATION' and 'call_llm' in obs_name:\n",
    "            llm_calls += 1\n",
    "        if obs_type == 'TOOL' and 'send_message' in obs_name:\n",
    "            tool_calls += 1\n",
    "        if obs_type == 'SPAN' and 'send_message' in obs_name:\n",
    "            pass \n",
    "\n",
    "    total_steps = llm_calls + tool_calls\n",
    "    print(f\"LLM calls: {llm_calls}, Tool calls (send_message): {tool_calls}\")\n",
    "    return total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3b169a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68b64ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM calls: 1, Tool calls (send_message): 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_agent_steps(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7b1a63cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM calls: 1, Tool calls (send_message): 1\n",
      "Evaluated trace 3c7300a2c603e23e4cd87f07cdc5c34f → goal_completion=1.000, tool_selection_accuracy=1.000, reasoning_quality=1.000, hallucinated_tool_output=0.000, conciseness=0.500, total_tokens=0.000, task_success_binary=1.000, plan_adherence=1.000, plan_quality=0.800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'goal_completion': 1.0,\n",
       " 'tool_selection_accuracy': 1.0,\n",
       " 'reasoning_quality': 1.0,\n",
       " 'hallucinated_tool_output': 0.0,\n",
       " 'conciseness': 0.5,\n",
       " 'total_steps': [\"Agent 'Capital Agent' is assigned a task User requested the capital of Pakistan and a 10-line description about it.\",\n",
       "  'Agent response: Islamabad',\n",
       "  \"Final Agent 'General Q&A Agent' was assigned a task User asked for a 10-line description of Islamabad, the capital of Pakistan.\"],\n",
       " 'latency_seconds': None,\n",
       " 'total_tokens': 0,\n",
       " 'task_success_binary': 1.0,\n",
       " 'plan_adherence': 1.0,\n",
       " 'plan_quality': 0.8}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import  datetime, timedelta\n",
    "from typing import Any, Dict, Optional, Tuple\n",
    " \n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from langfuse import Langfuse\n",
    "from langfuse.openai import AzureOpenAI\n",
    " \n",
    "load_dotenv()\n",
    " \n",
    "langfuse = Langfuse()  # Auto-reads LANGFUSE_* env vars\n",
    " \n",
    "AZURE_CLIENT = AzureOpenAI(\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version=\"2024-08-01-preview\",\n",
    ")\n",
    "JUDGE_MODEL = os.getenv(\"AZURE_OPENAI_MODEL\")\n",
    "\n",
    "def evaluate_agent_trace(trace_id: str) -> Dict[str, Any]:\n",
    "    trace = y\n",
    "    if trace is None:\n",
    "        print(f\"Trace {trace_id} could not be fetched; skipping score calculation.\")\n",
    "        return {}\n",
    "    question = input\n",
    "    final_answer = output\n",
    "    full_conversation = steps\n",
    " \n",
    "    scores: Dict[str, Any] = {}\n",
    " \n",
    "    scores[\"goal_completion\"] = llm_judge(\n",
    "        prompt_template=\"\"\"\n",
    "Question: {question}\n",
    "Final Answer: {answer}\n",
    " \n",
    "Did the agent fully solve the user's original goal or question?\n",
    "Score 0.0–1.0 (1.0 = completely solved, no missing parts)\n",
    "Respond ONLY with valid JSON: {{\"score\": 0.XX, \"explanation\": \"one short sentence\"}}\n",
    "        \"\"\",\n",
    "        question=question,\n",
    "        answer=final_answer,\n",
    "    )\n",
    " \n",
    "    scores[\"tool_selection_accuracy\"] = llm_judge(\n",
    "        prompt_template=\"\"\"\n",
    "Question: {question}\n",
    "All tool calls made: {tools_used}\n",
    " \n",
    "Did the agent select the correct tools and in a logical order?\n",
    "Score 0.0–1.0\n",
    "JSON only: {{\"score\": 0.XX, \"explanation\": \"...\"}}\n",
    "        \"\"\",\n",
    "        question=question,\n",
    "        tools_used=extract_tool_calls(trace),\n",
    "    )\n",
    " \n",
    "    scores[\"reasoning_quality\"] = llm_judge(\n",
    "        prompt_template=\"\"\"\n",
    "Full conversation (including thoughts and tool results):\n",
    "{conversation}\n",
    " \n",
    "Are the intermediate reasoning steps logical, coherent, and free of major jumps?\n",
    "Score 0.0–1.0\n",
    "JSON only.\n",
    "        \"\"\",\n",
    "        conversation=full_conversation,\n",
    "    )\n",
    " \n",
    "    scores[\"hallucinated_tool_output\"] = llm_judge(\n",
    "        prompt_template=\"\"\"\n",
    "Question: {question}\n",
    "Conversation with tool results: {conversation}\n",
    " \n",
    "Did the agent ever invent or hallucinate a tool result that wasn't actually returned?\n",
    "0.0 = yes (bad), 1.0 = no hallucinations\n",
    "JSON only.\n",
    "        \"\"\",\n",
    "        question=question,\n",
    "        conversation=full_conversation,\n",
    "    )\n",
    " \n",
    "    scores[\"conciseness\"] = llm_judge(\n",
    "        prompt_template=\"\"\"\n",
    "Final Answer: {answer}\n",
    " \n",
    "Is the final response concise and to-the-point (no unnecessary fluff/repetition)?\n",
    "Score 0.0–1.0\n",
    "JSON only.\n",
    "        \"\"\",\n",
    "        answer=final_answer,\n",
    "    )\n",
    " \n",
    "    start = getattr(trace, \"start_time\", None) or getattr(trace, \"timestamp\", None)\n",
    "    end = getattr(trace, \"end_time\", None) or datetime.now()\n",
    "    latency = (end - start).total_seconds() if (start and end) else None\n",
    " \n",
    "    scores[\"total_steps\"] = steps\n",
    "    scores[\"latency_seconds\"] = round(latency, 2) if latency is not None else None\n",
    "    usage = getattr(trace, \"usage\", None)\n",
    "    scores[\"total_tokens\"] = (\n",
    "        usage.total_tokens\n",
    "        if usage and getattr(usage, \"total_tokens\", None) is not None\n",
    "        else getattr(trace, \"total_tokens\", 0)\n",
    "    )\n",
    "    scores[\"task_success_binary\"] = 1.0 if scores.get(\"goal_completion\", 0) >= 0.90 else 0.0\n",
    "\n",
    "\n",
    "    scores[\"plan_adherence\"] = llm_judge(\n",
    "        prompt_template=\"\"\"\n",
    "    Full trace (thoughts + actions): {conversation}\n",
    "\n",
    "    First, extract the agent's explicit or implicit plan from the reasoning steps.\n",
    "    Then evaluate: Did the agent follow its own plan without major unnecessary deviations?\n",
    "    Score 0.0–1.0 (1.0 = perfectly adhered to a reasonable plan)\n",
    "    Respond ONLY with valid JSON: {{\"score\": 0.XX, \"explanation\": \"short reasoning about adherence\"}}\n",
    "        \"\"\",\n",
    "        conversation=full_conversation,\n",
    "    )\n",
    "\n",
    "    scores[\"plan_quality\"] = llm_judge(\n",
    "        prompt_template=\"\"\"\n",
    "    Task/Question: {question}\n",
    "    Extracted plan from agent's thoughts: {conversation}\n",
    "\n",
    "    Evaluate the quality of the plan itself (regardless of execution): Is it logical, efficient, comprehensive, and likely to solve the task with minimal steps?\n",
    "    Score 0.0–1.0 (1.0 = optimal or near-optimal plan)\n",
    "    Respond ONLY with valid JSON: {{\"score\": 0.XX, \"explanation\": \"short reasoning about plan quality\"}}\n",
    "        \"\"\",\n",
    "        question=question,\n",
    "        conversation=full_conversation,\n",
    "    )\n",
    "\n",
    " \n",
    "    score_descriptions = {\n",
    "    # Original LLM-as-judge metrics\n",
    "    \"goal_completion\":              \"Did the agent fully solve the user's original goal/question?\",\n",
    "    \"tool_selection_accuracy\":      \"Did the agent select the correct tools in a logical order?\",\n",
    "    \"reasoning_quality\":            \"Are intermediate reasoning steps logical, coherent, no major jumps?\",\n",
    "    \"hallucinated_tool_output\":     \"1.0 = no invented/hallucinated tool results (lower = bad)\",\n",
    "    \"conciseness\":                  \"Is the final answer concise with no unnecessary fluff/repetition?\",\n",
    "\n",
    "    # New requested LLM-as-judge metrics\n",
    "    \"argument_correctness\":         \"Are arguments passed to every tool call correct, complete, and appropriate?\",\n",
    "    \"plan_adherence\":               \"Did the agent faithfully follow its own (explicit or implicit) plan?\",\n",
    "    \"plan_quality\":                 \"How good is the plan itself: logical, efficient, comprehensive, minimal steps?\",\n",
    "\n",
    "    # Additional recommended LLM-as-judge metrics\n",
    "    \"tool_efficiency\":              \"Did the agent use the minimal reasonable number of tool calls (no redundancy)?\",\n",
    "    \"error_recovery\":               \"When tools failed or gave unexpected results, did the agent notice and recover well?\",\n",
    "    \"state_awareness\":              \"Did the agent track obtained information and avoid repeating queries/actions?\",\n",
    "    \"reasoning_traceability\":       \"Are the agent's thoughts clearly explained and easy for a human to follow?\",\n",
    "    \"answer_groundedness\":          \"Is every claim in the final answer directly supported by real tool results?\",\n",
    "    \"step_efficiency\":              \"Given task difficulty, is the number of steps/reasoning cycles reasonable?\",\n",
    "    \"total_steps\":                  \"Number of reasoning + tool steps (lower = more efficient)\",\n",
    "    \"latency_seconds\":              \"End-to-end latency in seconds (lower = faster)\",\n",
    "    \"total_tokens\":                 \"Total tokens consumed across the whole trajectory\",\n",
    "    \"task_success_binary\":          \"Strict binary success (1 if goal_completion ≥ 0.9 else 0)\",\n",
    "    }\n",
    " \n",
    "    for name, value in scores.items():\n",
    "        langfuse.create_score(\n",
    "            trace_id=trace_id,\n",
    "            name=name,\n",
    "            value=float(value) if isinstance(value, (int, float)) else 0.0,\n",
    "            comment=score_descriptions.get(name, \"\"),\n",
    "            data_type=\"NUMERIC\",\n",
    "        )\n",
    " \n",
    "    metric_summary = \", \".join(\n",
    "        f\"{name}={value:.3f}\"\n",
    "        for name, value in scores.items()\n",
    "        if isinstance(value, (int, float))\n",
    "    )\n",
    "    print(f\"Evaluated trace {trace_id} → {metric_summary}\")\n",
    "    return scores\n",
    " \n",
    " \n",
    "def llm_judge(prompt_template: str, **kwargs) -> float:\n",
    "    # if not AZURE_CLIENT or not JUDGE_MODEL:\n",
    "    #     print(\"Azure OpenAI configuration missing. Returning 0.0 score.\")\n",
    "    #     return 0.0\n",
    " \n",
    "    full_prompt = prompt_template.strip().format(**kwargs)\n",
    " \n",
    "    try:\n",
    "        response = AZURE_CLIENT.chat.completions.create(\n",
    "            model=JUDGE_MODEL,\n",
    "            temperature=0.0,\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            max_tokens=500,\n",
    "            messages=[{\"role\": \"system\", \"content\": full_prompt}],\n",
    "        )\n",
    "        content = response.choices[0].message.content.strip()\n",
    "        result = json.loads(content)\n",
    "        return float(result.get(\"score\", 0.0))\n",
    "    except Exception as e:\n",
    "        raw_content = locals().get(\"content\", \"N/A\")\n",
    "        print(f\"Judge failed: {e}\\nRaw: {raw_content}\")\n",
    "        return 0.0\n",
    "    \n",
    "evaluate_agent_trace(trace_id=\"3c7300a2c603e23e4cd87f07cdc5c34f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cdc433e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Azure OpenAI configuration missing. Returning 0.0 score.\n",
      "Azure OpenAI configuration missing. Returning 0.0 score.\n",
      "Azure OpenAI configuration missing. Returning 0.0 score.\n",
      "Azure OpenAI configuration missing. Returning 0.0 score.\n",
      "Azure OpenAI configuration missing. Returning 0.0 score.\n",
      "Evaluated trace 3c7300a2c603e23e4cd87f07cdc5c34f → goal_completion=0.000, tool_selection_accuracy=0.000, reasoning_quality=0.000, hallucinated_tool_output=0.000, conciseness=0.000, total_steps=0.000, total_tokens=0.000, task_success_binary=0.000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'goal_completion': 0.0,\n",
       " 'tool_selection_accuracy': 0.0,\n",
       " 'reasoning_quality': 0.0,\n",
       " 'hallucinated_tool_output': 0.0,\n",
       " 'conciseness': 0.0,\n",
       " 'total_steps': 0,\n",
       " 'latency_seconds': None,\n",
       " 'total_tokens': 0,\n",
       " 'task_success_binary': 0.0}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_agent_trace(trace_id=\"3c7300a2c603e23e4cd87f07cdc5c34f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b716a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
