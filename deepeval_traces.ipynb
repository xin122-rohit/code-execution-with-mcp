{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228ac492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from langfuse import Langfuse\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "langfuse = Langfuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "839179a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = langfuse.api.trace.get(\"4132f6246668a058006e2fb58e47db2c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f96e8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '4132f6246668a058006e2fb58e47db2c',\n",
       " 'timestamp': datetime.datetime(2025, 11, 20, 7, 4, 44, 24000, tzinfo=datetime.timezone.utc),\n",
       " 'name': 'call_llm',\n",
       " 'input': {'model': 'azure/gpt-4o-mini',\n",
       "  'config': {'system_instruction': '\\n        **Role:** Host agent for the agent-to-agent protocol; delegates queries to specialized remote agents with maximum efficiency.\\n\\n**Core Directives:**\\n\\n* **Task Delegation:** Use the `send_message` function to assign precise, actionable tasks to remote agents.\\n* **Full Context Provision:** If an agent repeatedly asks for user confirmation, it likely lacks conversation history. Include all relevant context in the task to prevent this.\\n* **Autonomous Multi-Agent Engagement:** Engage any required agents directly—never seek user permission or preference. If multiple agents are needed, orchestrate them seamlessly.\\n* **Intelligent Inter-Agent Collaboration:** Instruct agents to determine if they need data from another agent. **If Agent A says \"I need X to proceed\" and Agent B can provide X, immediately query Agent B, then resubmit the updated task to Agent A.**\\n* **Transparent Output:** Deliver the full, unedited response from the final agent(s) to the user.\\n* **Confirmation Handling:** Only relay confirmation requests to the user if not already provided. Never confirm on behalf of the user.\\n* **Minimal Context Sharing:** Share only task-relevant context with each agent. Omit irrelevant details.\\n* **No Redundancy:** Never ask agents to confirm actions or information.\\n* **Tool-Only Responses:** Rely exclusively on tools and agents. If data is missing, request clarification from the user—never assume.\\n* **Recency Priority:** Base decisions on the most recent user message.\\n* **Active Agent Routing:** Route follow-up queries to the currently active agent using task updates.\\n\\n**Efficiency Rule:** \\n> **Dependency Resolution Loop:**  \\n> If Agent A blocks on missing info → Identify Agent B that can supply it → Query B → Feed result back to A → Repeat until A completes or escalates.\\n        **Agent Roster:**\\n\\n        * Available Agents: `{\"name\": \"Capital Agent\", \"description\": \"Answers capital-city questions for any country\"}\\n{\"name\": \"General Q&A Agent\", \"description\": \"Answers everyday questions on any topic \\\\u2014 weather, facts, how-to, recommendations, and more.\"}`\\n        * Currently Active Seller Agent: `Capital Agent`\\n                \\n\\nYou are an agent. Your internal name is \"Routing_agent\". The description about you is \"This Routing agent orchestrates the decomposition of the user asking for department or manager information.\".',\n",
       "   'tools': [{'function_declarations': [{'description': 'Sends a task to remote seller agent.\\n\\nThis will send a message to the remote agent named agent_name.\\n\\nArgs:\\n    agent_name: The name of the agent to send the task to.\\n    task: The comprehensive conversation context summary\\n        and goal to be achieved regarding user inquiry and purchase request.\\n    tool_context: The tool context this method runs in.\\n\\nYields:\\n    A dictionary of JSON data.\\n',\n",
       "       'name': 'send_message',\n",
       "       'parameters': {'properties': {'agent_name': {'type': 'STRING'},\n",
       "         'task': {'type': 'STRING'}},\n",
       "        'required': ['agent_name', 'task'],\n",
       "        'type': 'OBJECT'},\n",
       "       'response': {}}]}],\n",
       "   'labels': {'adk_agent_name': 'Routing_agent'}},\n",
       "  'contents': [{'parts': [{'text': 'what is the capital of Pakistan and write 10 lines about it.'}],\n",
       "    'role': 'user'},\n",
       "   {'parts': [{'function_call': {'id': 'call_VplGGuQm2Isgdu7rQbRO5Do3',\n",
       "       'args': {'agent_name': 'Capital Agent',\n",
       "        'task': 'User is asking for the capital of Pakistan and would like 10 lines of information about it.'},\n",
       "       'name': 'send_message'}}],\n",
       "    'role': 'model'},\n",
       "   {'parts': [{'function_response': {'id': 'call_VplGGuQm2Isgdu7rQbRO5Do3',\n",
       "       'name': 'send_message',\n",
       "       'response': {'result': {'artifacts': [{'artifactId': 'efb7da96-5c2b-4bd3-a6ab-af2eba01a192',\n",
       "           'parts': [{'kind': 'text', 'text': 'Islamabad'}]}],\n",
       "         'contextId': '4b49ab15-279b-4112-8258-39e71a0a96a9',\n",
       "         'history': [{'contextId': '4b49ab15-279b-4112-8258-39e71a0a96a9',\n",
       "           'kind': 'message',\n",
       "           'messageId': '792f4d13-3a3f-4cf6-b14c-99cec66dddfd',\n",
       "           'parts': [{'kind': 'text', 'text': 'Islamabad'}],\n",
       "           'role': 'agent'}],\n",
       "         'id': '95101ea5-1b83-44cf-b81e-cc91967ae233',\n",
       "         'kind': 'task',\n",
       "         'status': {'state': 'completed'}}}}}],\n",
       "    'role': 'user'}]},\n",
       " 'output': {'content': {'parts': [{'function_call': {'id': 'call_0QqwJXaHPctVzuvfleWCzZd9',\n",
       "      'args': {'agent_name': 'General Q&A Agent',\n",
       "       'task': 'User has asked for information about Islamabad, the capital of Pakistan, specifically requesting 10 lines of details.'},\n",
       "      'name': 'send_message'}}],\n",
       "   'role': 'model'},\n",
       "  'partial': False,\n",
       "  'usage_metadata': {'candidates_token_count': 43,\n",
       "   'prompt_token_count': 919,\n",
       "   'total_token_count': 962}},\n",
       " 'metadata': {'attributes': {'gen_ai.system': 'gcp.vertex.agent',\n",
       "   'gen_ai.request.model': 'azure/gpt-4o-mini',\n",
       "   'gcp.vertex.agent.invocation_id': 'e-d5942ea9-f811-4680-93b0-2316b5cf19d3',\n",
       "   'gcp.vertex.agent.session_id': 'default_session',\n",
       "   'gcp.vertex.agent.event_id': '8c59af89-4389-4e52-8ec8-6d6845047537',\n",
       "   'gen_ai.usage.input_tokens': '919',\n",
       "   'gen_ai.usage.output_tokens': '43'},\n",
       "  'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "   'telemetry.sdk.name': 'opentelemetry',\n",
       "   'telemetry.sdk.version': '1.38.0',\n",
       "   'service.name': 'unknown_service'},\n",
       "  'scope': {'name': 'gcp.vertex.agent',\n",
       "   'version': '1.17.0',\n",
       "   'attributes': {}}},\n",
       " 'tags': [],\n",
       " 'public': False,\n",
       " 'environment': 'default',\n",
       " 'htmlPath': '/project/cmhwzwyvs01fjad07xfmlp94h/traces/4132f6246668a058006e2fb58e47db2c',\n",
       " 'latency': 12.722,\n",
       " 'totalCost': 0.0,\n",
       " 'observations': [{'id': 'db3930094ca7ed3f',\n",
       "   'traceId': '4132f6246668a058006e2fb58e47db2c',\n",
       "   'type': 'AGENT',\n",
       "   'name': 'rohit',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 7, 4, 46, 346000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 7, 4, 56, 728000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': {},\n",
       "   'input': {'args': [],\n",
       "    'kwargs': {'message_request': {'id': '4a20a0b0-0473-4dfd-8523-0096afecabc2',\n",
       "      'jsonrpc': '2.0',\n",
       "      'method': 'message/send',\n",
       "      'params': {'configuration': None,\n",
       "       'message': {'contextId': 'b49aa494-f544-4525-bddd-8ca9f9458c98',\n",
       "        'extensions': None,\n",
       "        'kind': 'message',\n",
       "        'messageId': '4a20a0b0-0473-4dfd-8523-0096afecabc2',\n",
       "        'metadata': None,\n",
       "        'parts': [{'kind': 'text',\n",
       "          'metadata': None,\n",
       "          'text': 'User has asked for information about Islamabad, the capital of Pakistan, specifically requesting 10 lines of details.'}],\n",
       "        'referenceTaskIds': None,\n",
       "        'role': 'user',\n",
       "        'taskId': None},\n",
       "       'metadata': None}}}},\n",
       "   'version': None,\n",
       "   'metadata': {'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'langfuse-sdk',\n",
       "     'version': '3.10.0',\n",
       "     'attributes': {'public_key': 'pk-lf-f69fce2c-2a85-44c6-8777-646b07f7ccaf'}}},\n",
       "   'output': {'id': '4a20a0b0-0473-4dfd-8523-0096afecabc2',\n",
       "    'jsonrpc': '2.0',\n",
       "    'result': {'artifacts': [{'artifactId': '3aed3934-028e-4561-9c30-7c0739783213',\n",
       "       'description': None,\n",
       "       'extensions': None,\n",
       "       'metadata': None,\n",
       "       'name': None,\n",
       "       'parts': [{'kind': 'text',\n",
       "         'metadata': None,\n",
       "         'text': \"Here are 10 key details about Islamabad, Pakistan's capital:\\n\\n1. **Planned Capital**: Islamabad was purpose-built as Pakistan's capital in the 1960s, replacing Karachi, and officially became the capital in 1967.\\n\\n2. **Strategic Location**: The city is located in the Pothohar Plateau in northern Pakistan, near the Margalla Hills and close to Rawalpindi.\\n\\n3. **Modern Design**: Designed by Greek architect Constantinos Apostolou Doxiadis, the city features a grid-like layout with numbered sectors and wide, tree-lined avenues.\\n\\n4. **Population**: Home to approximately 1.2 million people, making it one of Pakistan's major urban centers.\\n\\n5. **Government Hub**: Houses all major government buildings, including the Parliament House, Supreme Court, and Presidential Palace (Aiwan-e-Sadr).\\n\\n6. **Faisal Mosque**: Features the iconic Faisal Mosque, one of the largest mosques in the world and a symbol of the city.\\n\\n7. **Green City**: Known for its abundant greenery, parks, and clean environment compared to other Pakistani cities.\\n\\n8. **Educational Center**: Home to prestigious institutions like Quaid-i-Azam University and the International Islamic University.\\n\\n9. **Diplomatic Quarter**: Hosts numerous foreign embassies and diplomatic missions in its designated diplomatic enclave.\\n\\n10. **Economic Importance**: Serves as a major economic hub with growing IT, telecommunications, and service sectors.\"}]}],\n",
       "     'contextId': 'b49aa494-f544-4525-bddd-8ca9f9458c98',\n",
       "     'history': [{'contextId': 'b49aa494-f544-4525-bddd-8ca9f9458c98',\n",
       "       'extensions': None,\n",
       "       'kind': 'message',\n",
       "       'messageId': '4a20a0b0-0473-4dfd-8523-0096afecabc2',\n",
       "       'metadata': None,\n",
       "       'parts': [{'kind': 'text',\n",
       "         'metadata': None,\n",
       "         'text': \"Here are 10 key details about Islamabad, Pakistan's capital:\\n\\n1. **Planned Capital**: Islamabad was purpose-built as Pakistan's capital in the 1960s, replacing Karachi, and officially became the capital in 1967.\\n\\n2. **Strategic Location**: The city is located in the Pothohar Plateau in northern Pakistan, near the Margalla Hills and close to Rawalpindi.\\n\\n3. **Modern Design**: Designed by Greek architect Constantinos Apostolou Doxiadis, the city features a grid-like layout with numbered sectors and wide, tree-lined avenues.\\n\\n4. **Population**: Home to approximately 1.2 million people, making it one of Pakistan's major urban centers.\\n\\n5. **Government Hub**: Houses all major government buildings, including the Parliament House, Supreme Court, and Presidential Palace (Aiwan-e-Sadr).\\n\\n6. **Faisal Mosque**: Features the iconic Faisal Mosque, one of the largest mosques in the world and a symbol of the city.\\n\\n7. **Green City**: Known for its abundant greenery, parks, and clean environment compared to other Pakistani cities.\\n\\n8. **Educational Center**: Home to prestigious institutions like Quaid-i-Azam University and the International Islamic University.\\n\\n9. **Diplomatic Quarter**: Hosts numerous foreign embassies and diplomatic missions in its designated diplomatic enclave.\\n\\n10. **Economic Importance**: Serves as a major economic hub with growing IT, telecommunications, and service sectors.\"}],\n",
       "       'referenceTaskIds': None,\n",
       "       'role': 'agent',\n",
       "       'taskId': None}],\n",
       "     'id': '81666aeb-40c9-40a9-a18e-7afc18b419ac',\n",
       "     'kind': 'task',\n",
       "     'metadata': None,\n",
       "     'status': {'message': None, 'state': 'completed', 'timestamp': None}}},\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': 'f23b98dd577b35b3',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 10382.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'unit': 'TOKENS',\n",
       "   'promptTokens': 0,\n",
       "   'createdAt': '2025-11-20T07:10:43.132Z',\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T07:10:43.132Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h'},\n",
       "  {'id': '5d71be990ab8c9fd',\n",
       "   'traceId': '4132f6246668a058006e2fb58e47db2c',\n",
       "   'type': 'GENERATION',\n",
       "   'name': 'call_llm',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 7, 4, 44, 24000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 7, 4, 56, 746000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': 'azure/gpt-4o-mini',\n",
       "   'modelParameters': {},\n",
       "   'input': {'model': 'azure/gpt-4o-mini',\n",
       "    'config': {'system_instruction': '\\n        **Role:** Host agent for the agent-to-agent protocol; delegates queries to specialized remote agents with maximum efficiency.\\n\\n**Core Directives:**\\n\\n* **Task Delegation:** Use the `send_message` function to assign precise, actionable tasks to remote agents.\\n* **Full Context Provision:** If an agent repeatedly asks for user confirmation, it likely lacks conversation history. Include all relevant context in the task to prevent this.\\n* **Autonomous Multi-Agent Engagement:** Engage any required agents directly—never seek user permission or preference. If multiple agents are needed, orchestrate them seamlessly.\\n* **Intelligent Inter-Agent Collaboration:** Instruct agents to determine if they need data from another agent. **If Agent A says \"I need X to proceed\" and Agent B can provide X, immediately query Agent B, then resubmit the updated task to Agent A.**\\n* **Transparent Output:** Deliver the full, unedited response from the final agent(s) to the user.\\n* **Confirmation Handling:** Only relay confirmation requests to the user if not already provided. Never confirm on behalf of the user.\\n* **Minimal Context Sharing:** Share only task-relevant context with each agent. Omit irrelevant details.\\n* **No Redundancy:** Never ask agents to confirm actions or information.\\n* **Tool-Only Responses:** Rely exclusively on tools and agents. If data is missing, request clarification from the user—never assume.\\n* **Recency Priority:** Base decisions on the most recent user message.\\n* **Active Agent Routing:** Route follow-up queries to the currently active agent using task updates.\\n\\n**Efficiency Rule:** \\n> **Dependency Resolution Loop:**  \\n> If Agent A blocks on missing info → Identify Agent B that can supply it → Query B → Feed result back to A → Repeat until A completes or escalates.\\n        **Agent Roster:**\\n\\n        * Available Agents: `{\"name\": \"Capital Agent\", \"description\": \"Answers capital-city questions for any country\"}\\n{\"name\": \"General Q&A Agent\", \"description\": \"Answers everyday questions on any topic \\\\u2014 weather, facts, how-to, recommendations, and more.\"}`\\n        * Currently Active Seller Agent: `Capital Agent`\\n                \\n\\nYou are an agent. Your internal name is \"Routing_agent\". The description about you is \"This Routing agent orchestrates the decomposition of the user asking for department or manager information.\".',\n",
       "     'tools': [{'function_declarations': [{'description': 'Sends a task to remote seller agent.\\n\\nThis will send a message to the remote agent named agent_name.\\n\\nArgs:\\n    agent_name: The name of the agent to send the task to.\\n    task: The comprehensive conversation context summary\\n        and goal to be achieved regarding user inquiry and purchase request.\\n    tool_context: The tool context this method runs in.\\n\\nYields:\\n    A dictionary of JSON data.\\n',\n",
       "         'name': 'send_message',\n",
       "         'parameters': {'properties': {'agent_name': {'type': 'STRING'},\n",
       "           'task': {'type': 'STRING'}},\n",
       "          'required': ['agent_name', 'task'],\n",
       "          'type': 'OBJECT'},\n",
       "         'response': {}}]}],\n",
       "     'labels': {'adk_agent_name': 'Routing_agent'}},\n",
       "    'contents': [{'parts': [{'text': 'what is the capital of Pakistan and write 10 lines about it.'}],\n",
       "      'role': 'user'},\n",
       "     {'parts': [{'function_call': {'id': 'call_VplGGuQm2Isgdu7rQbRO5Do3',\n",
       "         'args': {'agent_name': 'Capital Agent',\n",
       "          'task': 'User is asking for the capital of Pakistan and would like 10 lines of information about it.'},\n",
       "         'name': 'send_message'}}],\n",
       "      'role': 'model'},\n",
       "     {'parts': [{'function_response': {'id': 'call_VplGGuQm2Isgdu7rQbRO5Do3',\n",
       "         'name': 'send_message',\n",
       "         'response': {'result': {'artifacts': [{'artifactId': 'efb7da96-5c2b-4bd3-a6ab-af2eba01a192',\n",
       "             'parts': [{'kind': 'text', 'text': 'Islamabad'}]}],\n",
       "           'contextId': '4b49ab15-279b-4112-8258-39e71a0a96a9',\n",
       "           'history': [{'contextId': '4b49ab15-279b-4112-8258-39e71a0a96a9',\n",
       "             'kind': 'message',\n",
       "             'messageId': '792f4d13-3a3f-4cf6-b14c-99cec66dddfd',\n",
       "             'parts': [{'kind': 'text', 'text': 'Islamabad'}],\n",
       "             'role': 'agent'}],\n",
       "           'id': '95101ea5-1b83-44cf-b81e-cc91967ae233',\n",
       "           'kind': 'task',\n",
       "           'status': {'state': 'completed'}}}}}],\n",
       "      'role': 'user'}]},\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {'gen_ai.system': 'gcp.vertex.agent',\n",
       "     'gen_ai.request.model': 'azure/gpt-4o-mini',\n",
       "     'gcp.vertex.agent.invocation_id': 'e-d5942ea9-f811-4680-93b0-2316b5cf19d3',\n",
       "     'gcp.vertex.agent.session_id': 'default_session',\n",
       "     'gcp.vertex.agent.event_id': '8c59af89-4389-4e52-8ec8-6d6845047537',\n",
       "     'gen_ai.usage.input_tokens': '919',\n",
       "     'gen_ai.usage.output_tokens': '43'},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'gcp.vertex.agent',\n",
       "     'version': '1.17.0',\n",
       "     'attributes': {}}},\n",
       "   'output': {'content': {'parts': [{'function_call': {'id': 'call_0QqwJXaHPctVzuvfleWCzZd9',\n",
       "        'args': {'agent_name': 'General Q&A Agent',\n",
       "         'task': 'User has asked for information about Islamabad, the capital of Pakistan, specifically requesting 10 lines of details.'},\n",
       "        'name': 'send_message'}}],\n",
       "     'role': 'model'},\n",
       "    'partial': False,\n",
       "    'usage_metadata': {'candidates_token_count': 43,\n",
       "     'prompt_token_count': 919,\n",
       "     'total_token_count': 962}},\n",
       "   'usage': {'input': 919,\n",
       "    'output': 43,\n",
       "    'total': 962,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': None,\n",
       "   'promptId': None,\n",
       "   'usageDetails': {'input': 919, 'output': 43, 'total': 962},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 12722.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 962,\n",
       "   'unit': 'TOKENS',\n",
       "   'promptTokens': 919,\n",
       "   'createdAt': '2025-11-20T07:10:43.132Z',\n",
       "   'completionTokens': 43,\n",
       "   'updatedAt': '2025-11-20T07:10:43.132Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h'},\n",
       "  {'id': '58d22f36c6dd41d5',\n",
       "   'traceId': '4132f6246668a058006e2fb58e47db2c',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport._send_request',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 7, 4, 46, 348000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 7, 4, 56, 726000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'version': '1.0.0', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': 'd90eb6bbc29417cb',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 10378.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'unit': 'TOKENS',\n",
       "   'promptTokens': 0,\n",
       "   'createdAt': '2025-11-20T07:10:43.132Z',\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T07:10:43.132Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h'},\n",
       "  {'id': 'd90eb6bbc29417cb',\n",
       "   'traceId': '4132f6246668a058006e2fb58e47db2c',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport.send_message',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 7, 4, 46, 347000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 7, 4, 56, 727000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'version': '1.0.0', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': 'db3930094ca7ed3f',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 10380.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'unit': 'TOKENS',\n",
       "   'promptTokens': 0,\n",
       "   'createdAt': '2025-11-20T07:10:43.132Z',\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T07:10:43.132Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h'},\n",
       "  {'id': 'f23b98dd577b35b3',\n",
       "   'traceId': '4132f6246668a058006e2fb58e47db2c',\n",
       "   'type': 'TOOL',\n",
       "   'name': 'execute_tool send_message',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 7, 4, 46, 344000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 7, 4, 56, 731000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': {},\n",
       "   'input': {'agent_name': 'General Q&A Agent',\n",
       "    'task': 'User has asked for information about Islamabad, the capital of Pakistan, specifically requesting 10 lines of details.'},\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {'gen_ai.operation.name': 'execute_tool',\n",
       "     'gen_ai.tool.description': 'Sends a task to remote seller agent.\\n\\nThis will send a message to the remote agent named agent_name.\\n\\nArgs:\\n    agent_name: The name of the agent to send the task to.\\n    task: The comprehensive conversation context summary\\n        and goal to be achieved regarding user inquiry and purchase request.\\n    tool_context: The tool context this method runs in.\\n\\nYields:\\n    A dictionary of JSON data.',\n",
       "     'gen_ai.tool.name': 'send_message',\n",
       "     'gen_ai.tool.type': 'FunctionTool',\n",
       "     'gen_ai.tool.call.id': 'call_0QqwJXaHPctVzuvfleWCzZd9',\n",
       "     'gcp.vertex.agent.event_id': 'c70cad76-100e-443c-9947-6f61ae9b805b'},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'gcp.vertex.agent',\n",
       "     'version': '1.17.0',\n",
       "     'attributes': {}}},\n",
       "   'output': {'result': '<not serializable>'},\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': '5d71be990ab8c9fd',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 10387.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'unit': 'TOKENS',\n",
       "   'promptTokens': 0,\n",
       "   'createdAt': '2025-11-20T07:10:43.132Z',\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T07:10:43.132Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h'},\n",
       "  {'id': '203d6e296d566192',\n",
       "   'traceId': '4132f6246668a058006e2fb58e47db2c',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport._get_http_args',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 7, 4, 46, 347000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 7, 4, 46, 347000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': 'd90eb6bbc29417cb',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 0.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'unit': 'TOKENS',\n",
       "   'promptTokens': 0,\n",
       "   'createdAt': '2025-11-20T07:10:40.264Z',\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T07:10:40.265Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h'},\n",
       "  {'id': '31d0beb29c07aee4',\n",
       "   'traceId': '4132f6246668a058006e2fb58e47db2c',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport._apply_interceptors',\n",
       "   'startTime': datetime.datetime(2025, 11, 20, 7, 4, 46, 347000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 20, 7, 4, 46, 347000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'version': '1.0.0', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': 'd90eb6bbc29417cb',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 0.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'totalTokens': 0,\n",
       "   'unit': 'TOKENS',\n",
       "   'promptTokens': 0,\n",
       "   'createdAt': '2025-11-20T07:10:40.265Z',\n",
       "   'completionTokens': 0,\n",
       "   'updatedAt': '2025-11-20T07:10:40.265Z',\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h'}],\n",
       " 'scores': [],\n",
       " 'bookmarked': False,\n",
       " 'createdAt': '2025-11-20T07:10:41.000Z',\n",
       " 'updatedAt': '2025-11-20T07:10:43.206Z',\n",
       " 'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       " 'sessionId': None,\n",
       " 'release': None,\n",
       " 'version': None,\n",
       " 'userId': None,\n",
       " 'externalId': None}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b84cd768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "def extract_spans(data):\n",
    "    results = []\n",
    "\n",
    "    observations = data.get(\"observations\", [])\n",
    "\n",
    "    # Each element inside the list is an observation\n",
    "    for obs in observations:\n",
    "        results.extend(find_spans(obs))\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def find_spans(obj, results=None):\n",
    "    if results is None:\n",
    "        results = []\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "\n",
    "        # Check for span type with non-empty input\n",
    "        if obj.get(\"type\") == \"span\" and obj.get(\"input\"):\n",
    "            results.append({\n",
    "                \"id\": obj.get(\"id\"),\n",
    "                \"input\": obj.get(\"input\")\n",
    "            })\n",
    "\n",
    "        # Recurse deeper\n",
    "        for v in obj.values():\n",
    "            find_spans(v, results)\n",
    "\n",
    "    elif isinstance(obj, list):\n",
    "        for item in obj:\n",
    "            find_spans(item, results)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ---- USAGE ----\n",
    "valid_spans = extract_spans(x)\n",
    "print(valid_spans)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf834c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "13",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 124\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;66;03m# ===============================================================\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# 6. RUN\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;66;03m# ===============================================================\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 124\u001b[0m     \u001b[43mevaluate_and_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[42], line 112\u001b[0m, in \u001b[0;36mevaluate_and_log\u001b[1;34m(trace)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_and_log\u001b[39m(trace: Dict):\n\u001b[1;32m--> 112\u001b[0m     test_case \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_test_case\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    113\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m get_metrics()\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning DeepEval evaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[42], line 53\u001b[0m, in \u001b[0;36mbuild_test_case\u001b[1;34m(trace)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_test_case\u001b[39m(trace: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMTestCase:\n\u001b[1;32m---> 53\u001b[0m     contents \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m13\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     54\u001b[0m     \u001b[38;5;66;03m# output = trace[\"output\"][\"content\"][\"parts\"][0][\"function_call\"][\"args\"][\"task\"]\u001b[39;00m\n\u001b[0;32m     55\u001b[0m     output \u001b[38;5;241m=\u001b[39m trace[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobservations\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction_response\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 13"
     ]
    }
   ],
   "source": [
    "# FINAL_WORKING_DEEPEVAL_NOV19_2025.py\n",
    "import ast\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# DeepEval - latest 2025 API\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import GEval, FaithfulnessMetric, ToxicityMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.test_case import LLMTestCaseParams  # ← CRITICAL\n",
    "import pprint\n",
    "# Langfuse\n",
    "from langfuse import Langfuse\n",
    "\n",
    "# ===============================================================\n",
    "# 1. YOUR TRACE (paste full string)\n",
    "# ===============================================================\n",
    "# raw_trace = '''{'id': '59b7f43597ffd7104da70b5ecd0b2d4b', ... 'externalId': None}'''\n",
    "# trace_dict: Dict[str, Any] = ast.literal_eval(raw_trace)\n",
    "\n",
    "# ===============================================================\n",
    "# 2. Extract steps\n",
    "# ===============================================================\n",
    "def extract_steps(contents: List[Dict]) -> str:\n",
    "    steps = []\n",
    "    for part in contents:\n",
    "        if part.get(\"role\") == \"user\":\n",
    "            for p in part[\"parts\"]:\n",
    "                if \"text\" in p:\n",
    "                    steps.append(f\"USER: {p['text']}\")\n",
    "                elif \"function_response\" in p:\n",
    "                    try:\n",
    "                        txt = p[\"function_response\"][\"response\"][\"result\"][\"artifacts\"][0][\"parts\"][0][\"text\"]\n",
    "                        steps.append(f\"TOOL OUTPUT:\\n{txt.strip()}\")\n",
    "                    except:\n",
    "                        pass\n",
    "        elif part.get(\"role\") == \"model\":\n",
    "            for p in part[\"parts\"]:\n",
    "                if \"function_call\" in p:\n",
    "                    fc = p[\"function_call\"]\n",
    "                    agent = fc[\"args\"][\"agent_name\"]\n",
    "                    task = fc[\"args\"][\"task\"]\n",
    "                    steps.append(f\"→ CALL: send_message('{agent}')\\n    Task: {task}\")\n",
    "                elif \"text\" in p:\n",
    "                    steps.append(f\"FINAL ANSWER: {p['task']}\")\n",
    "    return \"\\n\\n\".join(steps)\n",
    "\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 3. Build test case\n",
    "# ===============================================================\n",
    "def build_test_case(trace: Dict) -> LLMTestCase:\n",
    "    contents = trace[\"observations\"][\"input\"][\"contents\"]\n",
    "    # output = trace[\"output\"][\"content\"][\"parts\"][0][\"function_call\"][\"args\"][\"task\"]\n",
    "    output = trace[\"observations\"][\"input\"][\"parts\"][0][\"function_response\"][\"parts\"][\"text\"]\n",
    "    user_query = next((p[\"text\"] for c in contents if c[\"role\"] == \"user\" for p in c[\"parts\"] if \"text\" in p), \"\")\n",
    "\n",
    "    full_trace = \"=== FULL AGENT ORCHESTRATION TRACE ===\\n\" + extract_steps(contents)\n",
    "\n",
    "    return LLMTestCase(\n",
    "        input=user_query,\n",
    "        actual_output=output,\n",
    "        context=[full_trace],\n",
    "    )\n",
    "\n",
    "# ===============================================================\n",
    "# 4. METRICS — ONLY THIS WAY WORKS IN NOV 2025\n",
    "# ===============================================================\n",
    "def get_metrics():\n",
    "    return [\n",
    "        GEval(\n",
    "            name=\"Multi-Agent Orchestration Quality\",\n",
    "            criteria=\"Rate how well the routing agent orchestrated other agents using the trace in retrieval_context.\",\n",
    "            evaluation_steps=[\n",
    "                \"Did it call Get Dept Number first?\",\n",
    "                \"Then Get Department Manager with d001?\",\n",
    "                \"Only 2 calls total?\",\n",
    "                \"No loops, no user involvement?\",\n",
    "                \"Final answer is direct and correct?\"\n",
    "            ],\n",
    "            evaluation_params=[\n",
    "                LLMTestCaseParams.INPUT,\n",
    "                LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "                LLMTestCaseParams.RETRIEVAL_CONTEXT,\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",\n",
    "            threshold=0.8\n",
    "        ),\n",
    "        GEval(\n",
    "            name=\"Efficiency & Minimal Steps\",\n",
    "            criteria=\"Was the task solved in the absolute minimum number of steps?\",\n",
    "            evaluation_steps=[\n",
    "                \"Exactly 2 agent calls\",\n",
    "                \"No redundancy\",\n",
    "                \"Perfect dependency resolution\"\n",
    "            ],\n",
    "            evaluation_params=[\n",
    "                LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "                LLMTestCaseParams.RETRIEVAL_CONTEXT,\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",\n",
    "            threshold=0.9\n",
    "        ),\n",
    "        FaithfulnessMetric(threshold=0.9),\n",
    "        ToxicityMetric(threshold=0.1),\n",
    "    ]\n",
    "\n",
    "# ===============================================================\n",
    "# 5. Evaluate + Log\n",
    "# ===============================================================\n",
    "def evaluate_and_log(trace: Dict):\n",
    "    test_case = build_test_case(trace)\n",
    "    metrics = get_metrics()\n",
    "\n",
    "    print(\"Running DeepEval evaluation...\")\n",
    "    results = evaluate(test_cases=[test_case], metrics=metrics)  # ← Correct call\n",
    "    result = results.test_results[0]\n",
    "    pprint.pprint(result)\n",
    "\n",
    "# ===============================================================\n",
    "# 6. RUN\n",
    "# ===============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_and_log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10bde34",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You set x = ..., replace it with the actual trace dictionary!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(x)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mEllipsis\u001b[39m:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# You probably typed x = ... by mistake\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou set x = ..., replace it with the actual trace dictionary!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Now x is guaranteed to be the correct dict\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: You set x = ..., replace it with the actual trace dictionary!"
     ]
    }
   ],
   "source": [
    "# === ONE-TIME FIX: Turn whatever x is into the real dictionary ===\n",
    "import json\n",
    "import ast\n",
    "\n",
    "if isinstance(x, str):\n",
    "    # If you pasted the JSON as a string\n",
    "    try:\n",
    "        x = json.loads(x)\n",
    "    except:\n",
    "        x = ast.literal_eval(x)\n",
    "elif isinstance(x, set):\n",
    "    x = list(x)[0]\n",
    "elif x is Ellipsis:\n",
    "    # You probably typed x = ... by mistake\n",
    "    raise ValueError(\"You set x = ..., replace it with the actual trace dictionary!\")\n",
    "# Now x is guaranteed to be the correct dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2dffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_custom_logic(trace: dict):\n",
    "    \"\"\"\n",
    "    Custom extraction logic for your multi-agent trace (Vertex AI Agent Builder / A2A style)\n",
    "    Works reliably with the structure you posted.\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"user_query\": None,\n",
    "        \"final_answer\": None,      # What the user should see as the final response\n",
    "        \"full_prompt\": None,       # The full input sent to the model (system + history)\n",
    "        \"agent_steps\": [],         # All intermediate agent responses\n",
    "        \"capital_city\": None\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        # 1. Extract original user query\n",
    "        contents = trace[\"input\"][\"contents\"]\n",
    "        for msg in contents:\n",
    "            if msg[\"role\"] == \"user\" and \"parts\" in msg:\n",
    "                for part in msg[\"parts\"]:\n",
    "                    if \"text\" in part:\n",
    "                        result[\"user_query\"] = part[\"text\"]\n",
    "                        break\n",
    "                if result[\"user_query\"]:\n",
    "                    break\n",
    "\n",
    "        # 2. Extract all function responses (agent answers)\n",
    "        agent_responses = []\n",
    "        for msg in contents:\n",
    "            if \"parts\" in msg:\n",
    "                for part in msg[\"parts\"]:\n",
    "                    if \"function_response\" in part:\n",
    "                        resp = part[\"function_response\"][\"response\"]\n",
    "                        text = None\n",
    "                        # Dig into the artifacts\n",
    "                        if \"result\" in resp:\n",
    "                            artifacts = resp[\"result\"].get(\"artifacts\", [])\n",
    "                            for artifact in artifacts:\n",
    "                                for p in artifact.get(\"parts\", []):\n",
    "                                    if p.get(\"kind\") == \"text\":\n",
    "                                        text = p[\"text\"]\n",
    "                                        break\n",
    "                                if text:\n",
    "                                    break\n",
    "                        # Also check history (some agents put it there)\n",
    "                        if not text and \"history\" in resp[\"result\"]:\n",
    "                            for h in resp[\"result\"][\"history\"]:\n",
    "                                for p in h.get(\"parts\", []):\n",
    "                                    if p.get(\"kind\") == \"text\":\n",
    "                                        text = p[\"text\"]\n",
    "                        if text:\n",
    "                            agent_name = part[\"function_response\"].get(\"name\", \"unknown_agent\")\n",
    "                            agent_responses.append({\n",
    "                                \"agent\": agent_name,\n",
    "                                \"response\": text.strip()\n",
    "                            })\n",
    "\n",
    "        result[\"agent_steps\"] = agent_responses\n",
    "\n",
    "        # 3. Determine final answer\n",
    "        # In your flow: Capital Agent → General Q&A Agent\n",
    "        # The last agent response is almost always the final detailed answer\n",
    "        if agent_responses:\n",
    "            # First response is usually just the capital name\n",
    "            if len(agent_responses) >= 1:\n",
    "                result[\"capital_city\"] = agent_responses[0][\"response\"]\n",
    "\n",
    "            # Last response is the detailed 10 lines → this is what user wants\n",
    "            if len(agent_responses) >= 2:\n",
    "                result[\"final_answer\"] = agent_responses[-1][\"response\"]\n",
    "            else:\n",
    "                result[\"final_answer\"] = agent_responses[0][\"response\"]\n",
    "\n",
    "        # 4. Full prompt sent to the model (for debugging/cost analysis)\n",
    "        # It's in observations → GENERATION → input.contents\n",
    "        observations = trace.get(\"observations\", [])\n",
    "        for obs in observations:\n",
    "            if obs.get(\"type\") == \"GENERATION\" and \"input\" in obs:\n",
    "                input_data = obs[\"input\"]\n",
    "                if \"contents\" in input_data:\n",
    "                    # Reconstruct readable prompt\n",
    "                    prompt_lines = []\n",
    "                    if \"config\" in input_data and \"system_instruction\" in input_data[\"config\"]:\n",
    "                        prompt_lines.append(\"SYSTEM:\")\n",
    "                        prompt_lines.append(input_data[\"config\"][\"system_instruction\"])\n",
    "                        prompt_lines.append(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "                    for msg in input_data[\"contents\"]:\n",
    "                        role = msg[\"role\"].upper()\n",
    "                        for part in msg[\"parts\"]:\n",
    "                            if \"text\" in part:\n",
    "                                prompt_lines.append(f\"{role}: {part['text']}\")\n",
    "                            elif \"function_call\" in part:\n",
    "                                fc = part[\"function_call\"]\n",
    "                                prompt_lines.append(f\"{role} → TOOL CALL: {fc['name']}({fc['args']})\")\n",
    "                            elif \"function_response\" in part:\n",
    "                                fr = part[\"function_response\"]\n",
    "                                resp_text = \"...\"  # truncated\n",
    "                                if \"response\" in fr and \"result\" in fr[\"response\"]:\n",
    "                                    artifacts = fr[\"response\"][\"result\"].get(\"artifacts\", [])\n",
    "                                    for a in artifacts:\n",
    "                                        for p in a.get(\"parts\", []):\n",
    "                                            if p.get(\"kind\") == \"text\":\n",
    "                                                resp_text = p[\"text\"][:200] + \"...\" if len(p[\"text\"]) > 200 else p[\"text\"]\n",
    "                                prompt_lines.append(f\"TOOL RESPONSE: {resp_text}\")\n",
    "\n",
    "                    result[\"full_prompt\"] = \"\\n\".join(prompt_lines)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in extraction: {e}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# ============= USAGE EXAMPLE =============\n",
    "trace = {...}  # your huge trace dict here\n",
    "\n",
    "extracted = extract_custom_logic(x)\n",
    "\n",
    "print(\"User Query:\", extracted[\"user_query\"])\n",
    "print(\"\\nCapital City:\", extracted[\"capital_city\"])\n",
    "print(\"\\nFinal Answer to User:\\n\")\n",
    "print(extracted[\"final_answer\"])\n",
    "print(\"\\nAll Agent Steps:\")\n",
    "for step in extracted[\"agent_steps\"]:\n",
    "    print(f\"- {step['agent']} → {step['response'][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577268f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ellipsis' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m contents \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# 1. Extract the user query (always the first plain text from user)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# ------------------------------------------------------------------\u001b[39;00m\n\u001b[0;32m      6\u001b[0m user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\n\u001b[0;32m      7\u001b[0m     (p[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m contents \n\u001b[0;32m      8\u001b[0m      \u001b[38;5;28;01mif\u001b[39;00m c\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown query\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ellipsis' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1. Extract the user query (always the first plain text from user)\n",
    "# ------------------------------------------------------------------\n",
    "user_query = next(\n",
    "    (p[\"text\"] for c in contents \n",
    "     if c.get(\"role\") == \"user\" \n",
    "     for p in c.get(\"parts\", []) \n",
    "     if isinstance(p, dict) and p.get(\"text\")),\n",
    "    \"Unknown query\"\n",
    ")\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 2. Extract the real final answer (the last agent response that has text)\n",
    "# ------------------------------------------------------------------\n",
    "actual_output = \"No final answer found.\"\n",
    "\n",
    "# Go backwards through the conversation – the last meaningful tool response is our answer\n",
    "for message in reversed(contents):\n",
    "    if message.get(\"role\") == \"user\":                     # tool responses appear as \"user\" in Vertex traces\n",
    "        for part in message.get(\"parts\", []):\n",
    "            if \"function_response\" in part:\n",
    "                resp = part[\"function_response\"][\"response\"]\n",
    "                if \"result\" in resp:\n",
    "                    artifacts = resp[\"result\"].get(\"artifacts\", [])\n",
    "                    for artifact in artifacts:\n",
    "                        for subpart in artifact.get(\"parts\", []):\n",
    "                            if subpart.get(\"kind\") == \"text\" and subpart.get(\"text\"):\n",
    "                                actual_output = subpart[\"text\"].strip()\n",
    "                                break  # stop at the first (i.e. last in reverse) text we find\n",
    "                    if actual_output != \"No final answer found.\":\n",
    "                        break\n",
    "    if actual_output != \"No final answer found.\":\n",
    "        break\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Now you can use `user_query` and `actual_output` directly\n",
    "# ------------------------------------------------------------------\n",
    "print(\"User query   :\", user_query)\n",
    "print(\"Final answer :\", actual_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bed73b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
