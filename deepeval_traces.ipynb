{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228ac492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from langfuse import Langfuse\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "langfuse = Langfuse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "839179a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = langfuse.api.trace.get(\"8c7d7623175e8a8be5a57756694985ce\").dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f96e8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '8c7d7623175e8a8be5a57756694985ce',\n",
       " 'timestamp': datetime.datetime(2025, 11, 19, 10, 52, 36, 215000, tzinfo=datetime.timezone.utc),\n",
       " 'name': 'send_message',\n",
       " 'input': {'args': [],\n",
       "  'kwargs': {'message_request': {'id': 'f8f0f333-e973-4d4e-b505-4be358bdd492',\n",
       "    'jsonrpc': '2.0',\n",
       "    'method': 'message/send',\n",
       "    'params': {'configuration': None,\n",
       "     'message': {'contextId': 'c438b2c3-e9ca-4d53-acf6-34a5cc252660',\n",
       "      'extensions': None,\n",
       "      'kind': 'message',\n",
       "      'messageId': 'f8f0f333-e973-4d4e-b505-4be358bdd492',\n",
       "      'metadata': None,\n",
       "      'parts': [{'kind': 'text',\n",
       "        'metadata': None,\n",
       "        'text': 'User is inquiring about the capital of India and wants a detailed description in ten lines.'}],\n",
       "      'referenceTaskIds': None,\n",
       "      'role': 'user',\n",
       "      'taskId': None},\n",
       "     'metadata': None}}}},\n",
       " 'output': {'id': 'f8f0f333-e973-4d4e-b505-4be358bdd492',\n",
       "  'jsonrpc': '2.0',\n",
       "  'result': {'artifacts': [{'artifactId': '8c59de2a-2198-4d53-92c2-6a375b3f2b2f',\n",
       "     'description': None,\n",
       "     'extensions': None,\n",
       "     'metadata': None,\n",
       "     'name': None,\n",
       "     'parts': [{'kind': 'text', 'metadata': None, 'text': 'New Delhi'}]}],\n",
       "   'contextId': 'c438b2c3-e9ca-4d53-acf6-34a5cc252660',\n",
       "   'history': [{'contextId': 'c438b2c3-e9ca-4d53-acf6-34a5cc252660',\n",
       "     'extensions': None,\n",
       "     'kind': 'message',\n",
       "     'messageId': 'f8f0f333-e973-4d4e-b505-4be358bdd492',\n",
       "     'metadata': None,\n",
       "     'parts': [{'kind': 'text', 'metadata': None, 'text': 'New Delhi'}],\n",
       "     'referenceTaskIds': None,\n",
       "     'role': 'agent',\n",
       "     'taskId': None}],\n",
       "   'id': 'a6a2bebe-14a8-4ae6-8eed-eeeaa0b50524',\n",
       "   'kind': 'task',\n",
       "   'metadata': None,\n",
       "   'status': {'message': None, 'state': 'completed', 'timestamp': None}}},\n",
       " 'metadata': {'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "   'telemetry.sdk.name': 'opentelemetry',\n",
       "   'telemetry.sdk.version': '1.38.0',\n",
       "   'service.name': 'unknown_service'},\n",
       "  'scope': {'name': 'langfuse-sdk',\n",
       "   'version': '3.10.0',\n",
       "   'attributes': {'public_key': 'pk-lf-f69fce2c-2a85-44c6-8777-646b07f7ccaf'}}},\n",
       " 'tags': [],\n",
       " 'public': False,\n",
       " 'environment': 'default',\n",
       " 'htmlPath': '/project/cmhwzwyvs01fjad07xfmlp94h/traces/8c7d7623175e8a8be5a57756694985ce',\n",
       " 'latency': 7.311,\n",
       " 'totalCost': 0.0,\n",
       " 'observations': [{'id': 'fef3bdfc4b9a15be',\n",
       "   'traceId': '8c7d7623175e8a8be5a57756694985ce',\n",
       "   'type': 'AGENT',\n",
       "   'name': 'send_message',\n",
       "   'startTime': datetime.datetime(2025, 11, 19, 10, 52, 36, 215000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 19, 10, 52, 43, 526000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': {},\n",
       "   'input': {'args': [],\n",
       "    'kwargs': {'message_request': {'id': 'f8f0f333-e973-4d4e-b505-4be358bdd492',\n",
       "      'jsonrpc': '2.0',\n",
       "      'method': 'message/send',\n",
       "      'params': {'configuration': None,\n",
       "       'message': {'contextId': 'c438b2c3-e9ca-4d53-acf6-34a5cc252660',\n",
       "        'extensions': None,\n",
       "        'kind': 'message',\n",
       "        'messageId': 'f8f0f333-e973-4d4e-b505-4be358bdd492',\n",
       "        'metadata': None,\n",
       "        'parts': [{'kind': 'text',\n",
       "          'metadata': None,\n",
       "          'text': 'User is inquiring about the capital of India and wants a detailed description in ten lines.'}],\n",
       "        'referenceTaskIds': None,\n",
       "        'role': 'user',\n",
       "        'taskId': None},\n",
       "       'metadata': None}}}},\n",
       "   'version': None,\n",
       "   'metadata': {'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'langfuse-sdk',\n",
       "     'version': '3.10.0',\n",
       "     'attributes': {'public_key': 'pk-lf-f69fce2c-2a85-44c6-8777-646b07f7ccaf'}}},\n",
       "   'output': {'id': 'f8f0f333-e973-4d4e-b505-4be358bdd492',\n",
       "    'jsonrpc': '2.0',\n",
       "    'result': {'artifacts': [{'artifactId': '8c59de2a-2198-4d53-92c2-6a375b3f2b2f',\n",
       "       'description': None,\n",
       "       'extensions': None,\n",
       "       'metadata': None,\n",
       "       'name': None,\n",
       "       'parts': [{'kind': 'text', 'metadata': None, 'text': 'New Delhi'}]}],\n",
       "     'contextId': 'c438b2c3-e9ca-4d53-acf6-34a5cc252660',\n",
       "     'history': [{'contextId': 'c438b2c3-e9ca-4d53-acf6-34a5cc252660',\n",
       "       'extensions': None,\n",
       "       'kind': 'message',\n",
       "       'messageId': 'f8f0f333-e973-4d4e-b505-4be358bdd492',\n",
       "       'metadata': None,\n",
       "       'parts': [{'kind': 'text', 'metadata': None, 'text': 'New Delhi'}],\n",
       "       'referenceTaskIds': None,\n",
       "       'role': 'agent',\n",
       "       'taskId': None}],\n",
       "     'id': 'a6a2bebe-14a8-4ae6-8eed-eeeaa0b50524',\n",
       "     'kind': 'task',\n",
       "     'metadata': None,\n",
       "     'status': {'message': None, 'state': 'completed', 'timestamp': None}}},\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': None,\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 7311.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'promptTokens': 0,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'completionTokens': 0,\n",
       "   'totalTokens': 0,\n",
       "   'updatedAt': '2025-11-19T10:52:45.263Z',\n",
       "   'unit': 'TOKENS',\n",
       "   'createdAt': '2025-11-19T10:52:45.263Z'},\n",
       "  {'id': '478af020b8259ced',\n",
       "   'traceId': '8c7d7623175e8a8be5a57756694985ce',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport.send_message',\n",
       "   'startTime': datetime.datetime(2025, 11, 19, 10, 52, 36, 216000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 19, 10, 52, 43, 526000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'version': '1.0.0', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': 'fef3bdfc4b9a15be',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 7310.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'promptTokens': 0,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'completionTokens': 0,\n",
       "   'totalTokens': 0,\n",
       "   'updatedAt': '2025-11-19T10:52:45.263Z',\n",
       "   'unit': 'TOKENS',\n",
       "   'createdAt': '2025-11-19T10:52:45.263Z'},\n",
       "  {'id': 'e12a027abcd1adf5',\n",
       "   'traceId': '8c7d7623175e8a8be5a57756694985ce',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport._send_request',\n",
       "   'startTime': datetime.datetime(2025, 11, 19, 10, 52, 36, 218000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 19, 10, 52, 43, 525000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'version': '1.0.0', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': '478af020b8259ced',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 7307.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'promptTokens': 0,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'completionTokens': 0,\n",
       "   'totalTokens': 0,\n",
       "   'updatedAt': '2025-11-19T10:52:45.263Z',\n",
       "   'unit': 'TOKENS',\n",
       "   'createdAt': '2025-11-19T10:52:45.263Z'},\n",
       "  {'id': '1b02a71f000ff33a',\n",
       "   'traceId': '8c7d7623175e8a8be5a57756694985ce',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport._get_http_args',\n",
       "   'startTime': datetime.datetime(2025, 11, 19, 10, 52, 36, 216000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 19, 10, 52, 36, 217000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': '478af020b8259ced',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 1.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'promptTokens': 0,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'completionTokens': 0,\n",
       "   'totalTokens': 0,\n",
       "   'updatedAt': '2025-11-19T10:52:39.887Z',\n",
       "   'unit': 'TOKENS',\n",
       "   'createdAt': '2025-11-19T10:52:39.887Z'},\n",
       "  {'id': '664500986cabd6dd',\n",
       "   'traceId': '8c7d7623175e8a8be5a57756694985ce',\n",
       "   'type': 'SPAN',\n",
       "   'name': 'a2a.client.transports.jsonrpc.JsonRpcTransport._apply_interceptors',\n",
       "   'startTime': datetime.datetime(2025, 11, 19, 10, 52, 36, 217000, tzinfo=datetime.timezone.utc),\n",
       "   'endTime': datetime.datetime(2025, 11, 19, 10, 52, 36, 217000, tzinfo=datetime.timezone.utc),\n",
       "   'completionStartTime': None,\n",
       "   'model': None,\n",
       "   'modelParameters': None,\n",
       "   'input': None,\n",
       "   'version': None,\n",
       "   'metadata': {'attributes': {},\n",
       "    'resourceAttributes': {'telemetry.sdk.language': 'python',\n",
       "     'telemetry.sdk.name': 'opentelemetry',\n",
       "     'telemetry.sdk.version': '1.38.0',\n",
       "     'service.name': 'unknown_service'},\n",
       "    'scope': {'name': 'a2a-python-sdk', 'version': '1.0.0', 'attributes': {}}},\n",
       "   'output': None,\n",
       "   'usage': {'input': 0,\n",
       "    'output': 0,\n",
       "    'total': 0,\n",
       "    'unit': <ModelUsageUnit.TOKENS: 'TOKENS'>},\n",
       "   'level': <ObservationLevel.DEFAULT: 'DEFAULT'>,\n",
       "   'statusMessage': None,\n",
       "   'parentObservationId': '478af020b8259ced',\n",
       "   'promptId': None,\n",
       "   'usageDetails': {},\n",
       "   'costDetails': {},\n",
       "   'environment': 'default',\n",
       "   'promptName': None,\n",
       "   'promptVersion': None,\n",
       "   'modelId': None,\n",
       "   'inputPrice': 0.0,\n",
       "   'outputPrice': 0.0,\n",
       "   'totalPrice': 0.0,\n",
       "   'calculatedInputCost': None,\n",
       "   'calculatedOutputCost': None,\n",
       "   'calculatedTotalCost': 0.0,\n",
       "   'latency': 0.0,\n",
       "   'timeToFirstToken': None,\n",
       "   'promptTokens': 0,\n",
       "   'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       "   'completionTokens': 0,\n",
       "   'totalTokens': 0,\n",
       "   'updatedAt': '2025-11-19T10:52:39.887Z',\n",
       "   'unit': 'TOKENS',\n",
       "   'createdAt': '2025-11-19T10:52:39.887Z'}],\n",
       " 'scores': [],\n",
       " 'projectId': 'cmhwzwyvs01fjad07xfmlp94h',\n",
       " 'updatedAt': '2025-11-19T10:52:45.335Z',\n",
       " 'bookmarked': False,\n",
       " 'createdAt': '2025-11-19T10:52:40.000Z',\n",
       " 'sessionId': None,\n",
       " 'release': None,\n",
       " 'version': None,\n",
       " 'userId': None,\n",
       " 'externalId': None}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bf834c",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'task'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 150\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[38;5;66;03m# scores = {\u001b[39;00m\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m#     \"orchestration_quality\": result.score_breakdown[\"Multi-Agent Orchestration Quality\"],\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m#     \"efficiency_score\": result.score_breakdown[\"Efficiency & Minimal Steps\"],\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# 6. RUN\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# ===============================================================\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 150\u001b[0m     \u001b[43mevaluate_and_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 111\u001b[0m, in \u001b[0;36mevaluate_and_log\u001b[1;34m(trace)\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mevaluate_and_log\u001b[39m(trace: Dict):\n\u001b[1;32m--> 111\u001b[0m     test_case \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_test_case\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m get_metrics()\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning DeepEval evaluation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[10], line 54\u001b[0m, in \u001b[0;36mbuild_test_case\u001b[1;34m(trace)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mbuild_test_case\u001b[39m(trace: Dict) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMTestCase:\n\u001b[0;32m     53\u001b[0m     contents \u001b[38;5;241m=\u001b[39m trace[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m---> 54\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mtrace\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtask\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     55\u001b[0m     user_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((p[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m contents \u001b[38;5;28;01mif\u001b[39;00m c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m c[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparts\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m p), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     57\u001b[0m     full_trace \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=== FULL AGENT ORCHESTRATION TRACE ===\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m extract_steps(contents)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'task'"
     ]
    }
   ],
   "source": [
    "# FINAL_WORKING_DEEPEVAL_NOV19_2025.py\n",
    "import ast\n",
    "from typing import Dict, List, Any\n",
    "\n",
    "# DeepEval - latest 2025 API\n",
    "from deepeval import evaluate\n",
    "from deepeval.metrics import GEval, FaithfulnessMetric, ToxicityMetric\n",
    "from deepeval.test_case import LLMTestCase\n",
    "from deepeval.test_case import LLMTestCaseParams  # ← CRITICAL\n",
    "import pprint\n",
    "# Langfuse\n",
    "from langfuse import Langfuse\n",
    "\n",
    "# ===============================================================\n",
    "# 1. YOUR TRACE (paste full string)\n",
    "# ===============================================================\n",
    "# raw_trace = '''{'id': '59b7f43597ffd7104da70b5ecd0b2d4b', ... 'externalId': None}'''\n",
    "# trace_dict: Dict[str, Any] = ast.literal_eval(raw_trace)\n",
    "\n",
    "# ===============================================================\n",
    "# 2. Extract steps\n",
    "# ===============================================================\n",
    "def extract_steps(contents: List[Dict]) -> str:\n",
    "    steps = []\n",
    "    for part in contents:\n",
    "        if part.get(\"role\") == \"user\":\n",
    "            for p in part[\"parts\"]:\n",
    "                if \"text\" in p:\n",
    "                    steps.append(f\"USER: {p['text']}\")\n",
    "                elif \"function_response\" in p:\n",
    "                    try:\n",
    "                        txt = p[\"function_response\"][\"response\"][\"result\"][\"artifacts\"][0][\"parts\"][0][\"text\"]\n",
    "                        steps.append(f\"TOOL OUTPUT:\\n{txt.strip()}\")\n",
    "                    except:\n",
    "                        pass\n",
    "        elif part.get(\"role\") == \"model\":\n",
    "            for p in part[\"parts\"]:\n",
    "                if \"function_call\" in p:\n",
    "                    fc = p[\"function_call\"]\n",
    "                    agent = fc[\"args\"][\"agent_name\"]\n",
    "                    task = fc[\"args\"][\"task\"]\n",
    "                    steps.append(f\"→ CALL: send_message('{agent}')\\n    Task: {task}\")\n",
    "                elif \"text\" in p:\n",
    "                    steps.append(f\"FINAL ANSWER: {p['text']}\")\n",
    "    return \"\\n\\n\".join(steps)\n",
    "\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# 3. Build test case\n",
    "# ===============================================================\n",
    "def build_test_case(trace: Dict) -> LLMTestCase:\n",
    "    contents = trace[\"input\"][\"contents\"]\n",
    "    output = trace[\"output\"][\"content\"][\"parts\"][0][\"text\"]\n",
    "    user_query = next((p[\"text\"] for c in contents if c[\"role\"] == \"user\" for p in c[\"parts\"] if \"text\" in p), \"\")\n",
    "\n",
    "    full_trace = \"=== FULL AGENT ORCHESTRATION TRACE ===\\n\" + extract_steps(contents)\n",
    "\n",
    "    return LLMTestCase(\n",
    "        input=user_query,\n",
    "        actual_output=output,\n",
    "        retrieval_context=[full_trace],  # This is how you pass intermediate steps now\n",
    "    )\n",
    "\n",
    "# ===============================================================\n",
    "# 4. METRICS — ONLY THIS WAY WORKS IN NOV 2025\n",
    "# ===============================================================\n",
    "def get_metrics():\n",
    "    return [\n",
    "        GEval(\n",
    "            name=\"Multi-Agent Orchestration Quality\",\n",
    "            criteria=\"Rate how well the routing agent orchestrated other agents using the trace in retrieval_context.\",\n",
    "            evaluation_steps=[\n",
    "                \"Did it call Get Dept Number first?\",\n",
    "                \"Then Get Department Manager with d001?\",\n",
    "                \"Only 2 calls total?\",\n",
    "                \"No loops, no user involvement?\",\n",
    "                \"Final answer is direct and correct?\"\n",
    "            ],\n",
    "            evaluation_params=[\n",
    "                LLMTestCaseParams.INPUT,\n",
    "                LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "                LLMTestCaseParams.RETRIEVAL_CONTEXT,\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",\n",
    "            threshold=0.8\n",
    "        ),\n",
    "        GEval(\n",
    "            name=\"Efficiency & Minimal Steps\",\n",
    "            criteria=\"Was the task solved in the absolute minimum number of steps?\",\n",
    "            evaluation_steps=[\n",
    "                \"Exactly 2 agent calls\",\n",
    "                \"No redundancy\",\n",
    "                \"Perfect dependency resolution\"\n",
    "            ],\n",
    "            evaluation_params=[\n",
    "                LLMTestCaseParams.ACTUAL_OUTPUT,\n",
    "                LLMTestCaseParams.RETRIEVAL_CONTEXT,\n",
    "            ],\n",
    "            model=\"gpt-4o-mini\",\n",
    "            threshold=0.9\n",
    "        ),\n",
    "        FaithfulnessMetric(threshold=0.9),\n",
    "        ToxicityMetric(threshold=0.1),\n",
    "    ]\n",
    "\n",
    "# ===============================================================\n",
    "# 5. Evaluate + Log\n",
    "# ===============================================================\n",
    "def evaluate_and_log(trace: Dict):\n",
    "    test_case = build_test_case(trace)\n",
    "    metrics = get_metrics()\n",
    "\n",
    "    print(\"Running DeepEval evaluation...\")\n",
    "    results = evaluate(test_cases=[test_case], metrics=metrics)  # ← Correct call\n",
    "    result = results.test_results[0]\n",
    "    pprint.pprint(result)\n",
    "\n",
    "    # scores = {\n",
    "    #     \"orchestration_quality\": result.score_breakdown[\"Multi-Agent Orchestration Quality\"],\n",
    "    #     \"efficiency_score\": result.score_breakdown[\"Efficiency & Minimal Steps\"],\n",
    "    #     \"faithfulness\": result.score_breakdown[\"Faithfulness\"],\n",
    "    #     \"toxicity\": result.score_breakdown[\"Toxicity\"],\n",
    "    # }\n",
    "    # scores[\"task_success\"] = 1.0 if scores[\"orchestration_quality\"] >= 8.5 and scores[\"faithfulness\"] >= 0.9 else 0.0\n",
    "\n",
    "    # # Optional: Langfuse\n",
    "    # try:\n",
    "    #     langfuse = Langfuse()\n",
    "    #     lf_trace = langfuse.trace(name=\"Routing Agent Eval\", input=test_case.input, output=test_case.actual_output)\n",
    "    #     for k, v in scores.items():\n",
    "    #         lf_trace.score(name=k.replace(\"_\", \"-\"), value=float(v))\n",
    "    # except:\n",
    "    #     pass  # Ignore Langfuse warning\n",
    "\n",
    "    # print(\"\\n\" + \"=\"*60)\n",
    "    # print(\"EVALUATION COMPLETE - NOV 19, 2025\")\n",
    "    # print(\"=\"*60)\n",
    "    # print(f\"Orchestration Quality : {scores['orchestration_quality']:.2f}/10\")\n",
    "    # print(f\"Efficiency            : {scores['efficiency_score']:.2f}/10\")\n",
    "    # print(f\"Faithfulness          : {scores['faithfulness']:.2f}\")\n",
    "    # print(f\"Toxicity              : {scores['toxicity']:.2f}\")\n",
    "    # print(f\"Task Success          : {'YES' if scores['task_success'] else 'NO'}\")\n",
    "    # print(\"=\"*60)\n",
    "\n",
    "# ===============================================================\n",
    "# 6. RUN\n",
    "# ===============================================================\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_and_log(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577268f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
